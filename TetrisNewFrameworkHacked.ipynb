{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tetris Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from tetris.Tetris import Tetris,O\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend() \n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Tetris(pieces=[O])\n",
    "env.reset()\n",
    "BATCH_SIZE = 1024\n",
    "GAMMA = 0.99\n",
    "MULISTEP_GAMMA = 0.99\n",
    "\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.1\n",
    "EPS_DECAY = 2000000\n",
    "TARGET_UPDATE = 25\n",
    "NUM_STATES = len(env.actions)\n",
    "MULTISTEP_PARAM = 5\n",
    "MOVEMENT_COST = 0.01\n",
    "LAYER_HISTORY = 4\n",
    "TRAIN_RATE = 4\n",
    "LEARNING_RATE = 5 * 10**-4\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "def curr_eps(steps):\n",
    "    return 0\n",
    "#     return EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps / EPS_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        fleeting_memory = Transition(*args)\n",
    "        self.memory[self.position] = fleeting_memory\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    \n",
    "    \n",
    "class BiasedMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.good_memories = []\n",
    "        self.bad_memories = []\n",
    "        self.bias = []\n",
    "        self.bias_sum = 0\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args, bias=1):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "            self.bias.append(None)\n",
    "            self.bias_sum += bias\n",
    "        else:\n",
    "            # Don't add if small bias\n",
    "            if bias < self.bias_sum / len(self.memory) * (curr_eps(steps_done) - EPS_END):\n",
    "                return\n",
    "            self.bias_sum -= self.bias[self.position]\n",
    "            self.bias_sum += bias\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.bias[self.position] = bias\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size, biased=True):\n",
    "        if biased:\n",
    "            choice_indices = np.random.choice(len(self.memory), size=batch_size, replace=False, p=np.array(self.bias) / self.bias_sum)\n",
    "            return [self.memory[i] for i in choice_indices]\n",
    "        else:\n",
    "            return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyFactorizedLinear(nn.Linear):\n",
    "    \"\"\"\n",
    "    NoisyNet layer with factorized gaussian noise\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features, sigma_zero=0.4, bias=True):\n",
    "        super(NoisyFactorizedLinear, self).__init__(in_features, out_features, bias=bias)\n",
    "        sigma_init = sigma_zero / math.sqrt(in_features)\n",
    "        self.sigma_weight = nn.Parameter(torch.Tensor(out_features, in_features).fill_(sigma_init))\n",
    "        self.register_buffer(\"epsilon_input\", torch.zeros(1, in_features))\n",
    "        self.register_buffer(\"epsilon_output\", torch.zeros(out_features, 1))\n",
    "        if bias:\n",
    "            self.sigma_bias = nn.Parameter(torch.Tensor(out_features).fill_(sigma_init))\n",
    "\n",
    "    def forward(self, input):\n",
    "        torch.randn(self.epsilon_input.size(), out=self.epsilon_input)\n",
    "        torch.randn(self.epsilon_output.size(), out=self.epsilon_output)\n",
    "\n",
    "        func = lambda x: torch.sign(x) * torch.sqrt(torch.abs(x))\n",
    "        eps_in = func(self.epsilon_input)\n",
    "        eps_out = func(self.epsilon_output)\n",
    "\n",
    "        bias = self.bias\n",
    "        if bias is not None:\n",
    "            bias = bias + self.sigma_bias * Variable(eps_out.t())\n",
    "        noise_v = Variable(torch.mul(eps_in, eps_out))\n",
    "        return F.linear(input, self.weight + self.sigma_weight * noise_v, bias)\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, h, w, history=LAYER_HISTORY):\n",
    "        super().__init__()\n",
    "        self.input_layer_width = h * w\n",
    "        \n",
    "        # Encoder section\n",
    "        layer_widths = [\n",
    "            self.input_layer_width,\n",
    "            self.input_layer_width * 2,\n",
    "            self.input_layer_width * 2,\n",
    "            self.input_layer_width * 2,\n",
    "            256,\n",
    "        ]\n",
    "        self.shared_layers = nn.Sequential(\n",
    "            nn.Linear(layer_widths[0], layer_widths[1]),\n",
    "            nn.BatchNorm1d(num_features=layer_widths[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(layer_widths[1], layer_widths[2]),\n",
    "            nn.BatchNorm1d(layer_widths[2]),\n",
    "            nn.ReLU(),\n",
    "            NoisyFactorizedLinear(layer_widths[2], layer_widths[3]),\n",
    "            nn.BatchNorm1d(layer_widths[3]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Value Net\n",
    "        self.value_layer1 = nn.Linear(layer_widths[3], layer_widths[4])\n",
    "        self.vbn = nn.BatchNorm1d(layer_widths[4])\n",
    "        self.value_layer2 = nn.Linear(layer_widths[4], 1)\n",
    "        \n",
    "        # Advantage Net\n",
    "        self.advantage_layer1 = NoisyFactorizedLinear(layer_widths[3], layer_widths[4])\n",
    "        self.abn = nn.BatchNorm1d(layer_widths[4])\n",
    "        self.advantage_layer2 = NoisyFactorizedLinear(layer_widths[4], NUM_STATES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x = self.shared_layers(x.view(x.size(0), -1))\n",
    "        \n",
    "        value = F.relu(self.vbn(self.value_layer1(x)))\n",
    "        value = self.value_layer2(value)\n",
    "        \n",
    "        advg = F.relu(self.abn(self.advantage_layer1(x)))\n",
    "        advg = self.advantage_layer2(advg)\n",
    "        \n",
    "        return  value.expand(-1, NUM_STATES) + (advg - advg.mean(1, keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_state(grid, current_piece, next_piece):\n",
    "    fgrid = np.zeros((20,10))\n",
    "    for i,row in enumerate(grid):\n",
    "        for j in range(3,13):\n",
    "            fgrid[i][j-3] = 1.0 if row & (1<<j) else 0.0\n",
    "    return fgrid\n",
    "\n",
    "def get_screen(grid, human=False):\n",
    "    screen = create_state(grid, None, None)\n",
    "    \n",
    "    # Resize and add a batch dimension\n",
    "    tensor = torch.from_numpy(screen).unsqueeze(0).unsqueeze(0)\n",
    "    # Push to floats on GPU\n",
    "    return tensor.type(torch.FloatTensor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "init_screen = get_screen(env.get_grid())\n",
    "_, _, screen_height, screen_width = init_screen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/tetrisBotHackedNew1v6 loaded...\n"
     ]
    }
   ],
   "source": [
    "load_net_prefix = './models/tetrisBotHackedNew1v'\n",
    "load_net_number = 6\n",
    "net_to_load = f'{load_net_prefix}{load_net_number}'\n",
    "try:\n",
    "    policy_net = torch.load(net_to_load)\n",
    "    policy_net.eval()\n",
    "    target_net = torch.load(net_to_load)\n",
    "    target_net.eval()\n",
    "    print(f'{net_to_load} loaded...')\n",
    "except:\n",
    "    policy_net = DQN(screen_height, screen_width).to(device)\n",
    "    target_net = DQN(screen_height, screen_width).to(device)\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    target_net.eval()\n",
    "    print(f'Fell back to creating a new net...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(policy_net.parameters(), lr=LEARNING_RATE)\n",
    "memory = ReplayMemory(1000000)\n",
    "\n",
    "def select_action(state, deterministic=False):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = curr_eps(steps_done)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold and not deterministic:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net.eval()(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(NUM_STATES)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "lines_cleared = []\n",
    "eps_values = []\n",
    "\n",
    "def plot_durations(save=None):\n",
    "    fig = plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    plt.plot(np.array(lines_cleared) * 200)\n",
    "    plt.plot(np.array(eps_values) * 500)\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    \n",
    "    if save is not None:\n",
    "        fig.savefig(save, bbox_inches='tight')\n",
    "        \n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_single(state, action, next_state, reward):\n",
    "    return _compute_loss(state, action, next_state, reward, batch_size=1)\n",
    "\n",
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    next_state_batch = torch.cat(batch.next_state)\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    loss = _compute_loss(state_batch, action_batch, next_state_batch, reward_batch)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n",
    "\n",
    "def _compute_loss(_state, _action, _next_state, _reward, batch_size=BATCH_SIZE):\n",
    "    state_action_values = policy_net(_state).gather(1, _action)\n",
    "    next_state_values = target_net(_next_state)[0][policy_net(_next_state).argmax(1)[0]].detach()\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + _reward\n",
    "    return F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def did_piece_fall(this_env):\n",
    "    return this_env.placing_frame\n",
    "\n",
    "def get_height(this_env):\n",
    "    return np.argmin(this_env._grid[3:] != 57351)\n",
    "\n",
    "def create_reward(this_env, block_placed, action, is_done,\n",
    "                  old_height, old_lines, include_height=True, include_score=True):\n",
    "    if not block_placed:\n",
    "        # Punish a little for doing something that isn't the empty move, or down\n",
    "        if action == 0:\n",
    "            return 0\n",
    "    if is_done:\n",
    "        return -1.0\n",
    "    \n",
    "    total_reward = 0\n",
    "    if include_height:\n",
    "        this_height = get_height(this_env)\n",
    "        if this_height > old_height: \n",
    "            # Punish a little more the closer you are to the top\n",
    "            total_reward += (1 + this_height / 10) * (old_height - this_height) \n",
    "    \n",
    "    line_diff = env._total_lines_cleared - old_lines\n",
    "    if include_score and line_diff != 0:\n",
    "        total_reward += 2 ** (line_diff + 1)\n",
    "\n",
    "    return total_reward\n",
    "    \n",
    "def train(num_episodes=1000, human=False): \n",
    "    for i_episode in range(num_episodes):\n",
    "        # Initialize the environment and state\n",
    "        height, lines = 0, 0\n",
    "        env.reset()\n",
    "        last_state = get_screen(env.get_grid(), human=human)\n",
    "        state = get_screen(env.get_grid(), human=human)\n",
    "        hole_count = 0 \n",
    "        hole_reward = 0\n",
    "        tower_count = 0 \n",
    "        tower_reward = 0\n",
    "        if not human:\n",
    "            state_array = [last_state] * MULTISTEP_PARAM\n",
    "            reward_array = [0] * MULTISTEP_PARAM\n",
    "            \n",
    "            reward_sum = 0\n",
    "            array_pos = 0\n",
    "            next_array_pos = 1\n",
    "            warmup = 1\n",
    "        for t in count():\n",
    "\n",
    "            # Select and perform an action\n",
    "            action = select_action(state, deterministic=human)\n",
    "            # Can only perform an action once every three frames anyway...\n",
    "            state, _, done = env.step(action.item())\n",
    "            piece_fell = did_piece_fall(env)\n",
    "            if not done:\n",
    "                state, _, done = env.step(0)\n",
    "                piece_fell = (piece_fell or did_piece_fall(env))\n",
    "            if not done:\n",
    "                state, _, done = env.step(0)\n",
    "                piece_fell = (piece_fell or did_piece_fall(env))\n",
    "\n",
    "            # Observe new state\n",
    "            state = get_screen(state, human)\n",
    "            \n",
    "            if not human:\n",
    "                state_array[array_pos] = state\n",
    "            \n",
    "                reward_single = create_reward(env, piece_fell, action, done, height, lines)\n",
    "                reward_sum = (MULISTEP_GAMMA * reward_sum) + reward_single - (MULISTEP_GAMMA ** MULTISTEP_PARAM) * reward_array[array_pos]\n",
    "                reward_array[array_pos] = reward_single\n",
    "                reward_sum = torch.tensor([reward_sum], device=device).type(torch.float)\n",
    "                \n",
    "                # Store the transition in memory\n",
    "                if warmup > MULTISTEP_PARAM:\n",
    "#                     with torch.no_grad():\n",
    "#                         loss = compute_loss_single(state_array[next_array_pos], action, state, reward_sum) ** ((1 - curr_eps(steps_done)) / 2 + 0.05)\n",
    "#                     memory.push(state_array[next_array_pos], action, state, reward_sum, bias=np.array([loss.cpu()])[0])\n",
    "                    memory.push(state_array[next_array_pos], action, state, reward_sum)\n",
    "                \n",
    "                # Perform one step of the optimization (on the target network)\n",
    "                if (warmup + 1) % TRAIN_RATE == 0:\n",
    "                    optimize_model()\n",
    "                if done:\n",
    "                    episode_durations.append(t + 1)\n",
    "                    lines_cleared.append(lines)\n",
    "                    eps_values.append(curr_eps(steps_done))\n",
    "                    plot_durations('latestConv.png')\n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            # Set up params for next cycle\n",
    "            height = get_height(env)\n",
    "            lines = env._total_lines_cleared\n",
    "            last_state = state\n",
    "            if not human:\n",
    "                array_pos = (array_pos + 1) % MULTISTEP_PARAM\n",
    "                next_array_pos = (next_array_pos + 1) % MULTISTEP_PARAM\n",
    "                warmup += 1\n",
    "            \n",
    "        if not human:\n",
    "            # Update the target network, copying all weights and biases in DQN\n",
    "            if i_episode % TARGET_UPDATE == 0:\n",
    "                target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "def watch_model(rounds=1000):\n",
    "    with torch.no_grad():\n",
    "        train(rounds, human=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8VHX2//HXIfTeIRBCkCIgnUBA7IhUAVesuJZ1l/3+VECx67q23RV1xYK6K67u4ooIVoqIKEVAJRh6F4wkEEpCDy31/P64N2uIgUwwM3fKeT4e88jMnTtz3xlITu499/O5oqoYY4wxRZXzOoAxxpjgZAXCGGNMsaxAGGOMKZYVCGOMMcWyAmGMMaZYViCMMcYUywqEMaUgIlEiclREYstyXWOCkdg4CBPORORooYdVgSwgz338R1WdEvhUxoQGKxAmYojIduD3qvrVGdYpr6q5gUtlTPCyQ0wmoonIX0RkmohMFZFM4CYR6S0iy0TkkIjsFpFXRKSCu355EVERiXMfv+s+/7mIZIrIdyLSorTrus8PFJEfROSwiEwUkW9E5NbAfiLG/MwKhDFwFfAeUAuYBuQCY4H6QB9gAPDHM7z+RuAxoC6QCjxd2nVFpCEwHbjf3e5PQM+z/YaMKQtWIIyBpao6S1XzVfWEqn6vqomqmquqycAk4OIzvP5DVU1S1RxgCtDlLNYdAqxW1Rnucy8C+379t2bM2SvvdQBjgsCOwg9EpC3wAtAdp7FdHkg8w+v3FLp/HKh+Fus2KZxDVVVEdpaY3Bg/sj0IY6DomRpvAOuBVqpaE/gzIH7OsBuIKXggIgI09fM2jTkjKxDG/FIN4DBwTETaceb+Q1mZDXQTkStFpDxOD6RBALZrzGlZgTDml+4FbgEycfYmpvl7g6q6F7gOmADsB1oCq3DGbSAil4jIoYL1ReQxEZlV6PE8EXnA3zlNZLFxEMYEIRGJAnYBI1R1idd5TGSyPQhjgoSIDBCR2iJSCedU2BxgucexTASzAmFM8LgASAYygP7AVaqa5W0kE8nsEJMxxphi2R6EMcaYYvltoJyInMupZ3+cg3M++Tvu8jhgO3Ctqh50z/t+GRiEM4DoVlVdeaZt1K9fX+Pi4so8uzHGhLMVK1bsU9UST6MOyCEm94yMNCABuBM4oKrjReQhoI6qPigig4DROAUiAXhZVRPO9L7x8fGalJTk5/TGGBNeRGSFqsaXtF6gDjH1BX5U1RRgGDDZXT4ZGO7eHwa8o45lQG0RiQ5QPmOMMUUEqkBcD0x17zdS1d3u/T1AI/d+U06dE2cnNtWAMcZ4xu8FQkQqAkOBD4o+p87xrVId4xKRUSKSJCJJGRkZZZTSGGNMUYHYgxgIrHSnEgDYW3DoyP2a7i5PA5oVel2Mu+wUqjpJVeNVNb5BA5uqxhhj/CUQBeIGfj68BDATZ54b3K8zCi2/WRy9gMOFDkUZY4wJML9eD0JEqgH9OHU2zPHAdBG5HUgBrnWXz8E5g2kbzmmut/kzmzHGmDPza4FQ1WNAvSLL9uOc1VR0XcU5BdYYY0wQsJHUxhhPHTmZw3+XpXDkZI7XUUwRdslRY4xnliXv597pa0g7dIKvt2Tw5s3dcSZVMMHA9iCMMQGXlZvH3+Zs4oY3l1EhSrj1/Di+2rSXt5b+5HU0U4jtQRhjAmrT7iPcM201m/dkMjIhlkcHt6NKhSh2HTrB+M830615HbrF1vE6psH2IIwxAZKXr/zz6x8Z+upS9h/L5t+39uCvV3WkasXyiAjPj+hM41qVGf3eKg4dz/Y6rsEKhDEmAHYcOM4Nk5Yx/vPN9G3biC/uvohL2zY8ZZ1aVSvw2o3dSM88yX0frMGuVeM9KxDGGL9RVT5I2sHAl5ewcfcRXrimM/+4qRt1q1Usdv3OzWrzyKB2fLUpnX8tsX6E16wHYYzxi/1Hs3jkk3V8sWEvPVvUZcK1nYmpU7XE1916fhyJyQd4dq7Tj+je3PoRXrE9CGNMmZu/aS/9X1rCws0ZPDKoLVP/0Mun4gAgIjw7ohPRtSsz+r2V1o/wkBUIY0yZOZaVy8Mfr+P2yUnUr16RmaP7MOqilkSVK93YhlpVnH5ExtEs7p2+hvx860d4wQqEMaZMrEg5yKBXlvD+96n88eJzmHFXH9o2rnnW79cppjaPDmrH/M3p/GtpchkmNb6yHoQx5lfJzs3nlflbeX3RNprUrsL7f+hFwjn1Sn6hD245P47Enw7w7NwtdG9eh+7N65bJ+xrf2B6EMeasbUvP5Df/+IZXF27j6m4xfD72wjIrDvBzP6Jp7SqMfm8VB49ZPyKQrEAYY0otP1/59zc/MfiVpew6dJJ/3tSd56/pTI3KFcp8WzUrO/2IfUezufcD60cEkhUIY0yp7D58gpvfXs6TszZyQav6zL37QgZ0aOzXbXaMqcWjg9uxYHM6by6xfkSgWA/CGOOzGavTeOzT9eTmK8/8piPX92gWsNlXb+7dnMSf9vPcF1uIj7N+RCDYHoQxpkSHj+cweuoqxr6/mlYNqzNnzIXc0DM2oFNziwjjr3b6EXe9t4oD1o/wOysQxpgzWrI1g/4vLebzdbu574o2TP9jb+LqV/MkS0E/Yv/RbO6dvtr6EX5mBcIYU6yTOXk8MXMDv31rOdUrl+eTO/pw12WtKR/l7a+NjjG1+NOQdizcksEk60f4lfUgjDG/sG7nYe6etoofM45xW584HhzQlsoVoryO9T+/7dWcxOQDPP/FFuKb1yE+zvoR/mB7EMaY/8nNy2fi/K1c9fo3HMvK493bE3j8yvOCqjiA04945uqOxNSxfoQ/+bVAiEhtEflQRDaLyCYR6S0idUXkSxHZ6n6t464rIvKKiGwTkbUi0s2f2Ywxp9q+7xjXvPEdL3z5A4M6RvPF3RdxQev6Xsc6rYJ+xIFj2YyzfoRf+HsP4mVgrqq2BToDm4CHgPmq2hqY7z4GGAi0dm+jgH/4OZvxQebJHD5dlcYzn29iVepBu4hLGFJVpiSmMPDlJfyYfpRXbujKKzd0pVbVsh/0VtY6NK3FY0PasWhLBm8stn5EWfNbD0JEagEXAbcCqGo2kC0iw4BL3NUmA4uAB4FhwDvq/AZa5u59RKvqbn9lNMXLPJnD/E3pzF67m8VbM8jOzUcE3vg6mfbRNRnZK5ZhXZpSvZK1sEJdeuZJHvxwLQu3ZHBh6/o8N6IT0bWqeB2rVG7q1ZxlyQf4+zxnfEQP60eUGfHXX4Qi0gWYBGzE2XtYAYwF0lS1truOAAdVtbaIzAbGq+pS97n5wIOqmlTkfUfh7GEQGxvbPSUlxS/5I01BUfhs3W6+/sEpCo1rVmZgx8YM6RRN60Y1mLl6F1MSU9m0+wjVK5VneNcmjExoTrvos5+x03hn7vrdPPzxOo5n5/HwwLbc3DuOcqWcljtYZJ7MYcjEpWTl5PPZmAuoV72S15GCmoisUNX4EtfzY4GIB5YBfVQ1UUReBo4AowsKhLveQVWt42uBKCw+Pl6Tkk77tCnB0axc5m/ay+y1vywKgztG0y22zi9+Yagqq3YcYsqyVGav3UVWbj7dYmszMqE5gztFB10z0/xS5skcnpy1kQ9X7KRj01q8eF0XWjWs7nWsX2192mF+8/q39G5Zj3/f2iNki10gBEOBaAwsU9U49/GFOP2GVsAlqrpbRKKBRap6roi84d6f6q6/pWC9023DCkTpFRSFz9buZpFbFBrVrMSgjtGnLQqnc+h4Nh+tTGNKYgrJGceoVaUCI7rHcGNCLC0bhP4vnHCUmLyfcdPXsPvwCe66tBWj+7amgsfjGsrSf5el8Nin63lgwLnccUkrr+MELc8LhBtiCfB7Vd0iIk8ABcMv96vqeBF5CKirqg+IyGDgLmAQkAC8oqo9z/T+ViB8c7qiMLBDNEM6la4oFEdV+S55P1MSU/li/R5y85XzW9ZjZEJz+rVvRMXy4fMLKFRl5eYxYd4PTFqSTPO6VZlwXRe6xYbftZ5VldFTV/H5+j1M/UMverawfkRxgqVAdAH+BVQEkoHbcM6cmg7EAinAtap6wO1HvAoMAI4Dt53p8BJYgTiTMxWFwZ2i6f4ri8LpZGRmMT1pB+8lppJ26AT1q1fiuh4xXN8jlmZ1fbsmsSlbm3Yf4Z5pq9m8J5MbE2J5dFA7qoXxCQaZJ3O4cuJSTuTkMWfMhdaPKEZQFAh/swJxqoKiMGfdbhZtySArN5+GNdzDR34sCsXJy1cWb81gyrJUFmzeiwKXtGnATb2ac8m5DUt9jWJTenn5yr+WJPPCvB+oWaUCz43oyGVtG3kdKyDWpx3mN//4ll7n1OM/1o/4BSsQEeJYVi7zN6fz2dpdnheF00k7dIJpy1N5//sdpGdm0aRWZW7oGct1PZrRsGZlT7OFqx0HjnPvB2tY/tMB+p/XiL9d1THi/pJ+d1kKf/p0Pff3P5c7L7V+RGFWIMJYQVGYs3Y3C7ekn1IUBnWMJr6590WhODl5+czftJcpiaks2bqP8uWEfu0bMTKhOee3rBeUmUONqvLRyjSemLkBgCeGnsfV3ZoGdFruYKGqjHl/NZ+t3cX7o3pbP6IQKxBh5nRFYWCHxgzu1CRoi8LpbN93jKnLU5metIODx3OIq1eVGxNiGdG9GXWrVfQ6Xkg6cCybRz5ex9wNe+jZoi4vXNM54vs+mSdzGPrqNxzPzuWzMRdSP8L2ok7HCkQYOJaVy4LN6XxWqCg0qFGJQR0aO3sKcXVD/lj+yZw85q7fw5TEFL7ffpCK5csxuGM0IxNi6d68TkT+5Xs2Fm5O5/4P13LkRA739W/D7RecE/L/N8rKhl2Huer1b0loUZfJt/UMqT+k/MUKRIgqKApz1jlF4WRO+BWF09myJ5P3ElP4eGUamVm5nNuoBiN7xTK8a1NqVg7+eYG8cCwrl7/O2cR7iam0bVyDF6/rYiPbizElMYVHP7F+RAErECHkdEVhYAdnRHM4F4XiHM/OZdaaXby7LJV1aYepUiGKYV2caT06xtTyOl7QWJl6kHHTVpNy4DijLjyHcVe0oVJ5G8leHFVl7Purmb12F1P/0IuEc+p5HclTViCC3PHsn4vCgs2nFoVBHaPpEWFF4XTW7nSm9Zi5ZhcncvLoHFOLkQnNGdI5mqoVw/dc/jPJca/Z8OrCbUTXqsKEaztH/C88XxzNyuXKiUs5lpXLnLGR3Y+wAhGEiisK9atXYlBHKwolOXzCmXZ8SmIKP+w9So3K5bm6mzOtR5tGNbyOFzDb0o9yz7TVrEs7zIjuMTx+ZXtq2OE3n23cdYThr38T8f0IKxBB4nh2Lgs3Z/DZul2nFAXn7CMrCqWlqiSlHGTKshTmrNtDdl4+PePqMrJXLAM6NA7bQyz5+co7323nmc83U61Sef52VUcGdGjsdayQ9F5iKo98so77rmjDXZe19jqOJ6xAeKigKBTsKZzIyaN+9YoM7OCMU+jZwopCWdh/NIsPV+zkveWppOw/Tt1qFbkmPoYbe8bSvF61kt8gROw5fJL7P1zDkq37uKxtQ8Zf3ZGGNWyA4dlSVe6etppZa3Yx5fe96N0y8g7PWYEIsNMVhQEdGjO4YxMrCn6Un6988+M+pixL5ctNe8nLVy5sXZ+RCc25vF1DyofwbKWz1uziT5+uJzs3n8eGtOeGns3s1N8ycDQrl6ETl5KZlcucMRfSoEZk9SOsQATAiew8Fm5xxikULQqDOkaT0KKeFYUA23vkJNO+38HU5ansPnySRjUrcV2PWK7v0YwmtUPnSmmHj+fw2Iz1zFyzi66xtXnx2i7E1Q+fvaJgsGn3EYa/9g094uoy+Xc9I+pn1QqEn/yvKKzbzYJNVhSCVW5ePgu3ZDAlMYWvf8hAgL7tGjEyIZaLWjcI6ubk0q37uO+DNew7msXdl7fm/y5uGdJ7QcFs6vJUHv54Hff2a8PovpHTj/C1QETmeYKldCI7j0Vb0pldpCj8pltTBneyohCMykeVo1/7RvRr34gdB47/b1qPLzfuJaZOFW5MiOWa7s2C6tDCyZw8np27mX9/s52WDarx5s19bNyHn13foxmJyft58asf6B5Xh/Nb1vc6UlCxPYjTKCgKn7k9hePZedSrVtBTcBrN9lddaMnOzWfexj1MWZbKd8n7qRAl9D+vMSMTmtPrnLqeHttfn3aYu6etZlv6UW49P46HBra1y7cGyLGsXK58dSmZJyOnH2GHmM6CFYXIsS39KO8lpvLhih0cOZnLOQ2qMTKhOSO6xVCrauDGFeTm5fPPr3/kpa+2Ur96JZ6/phMXtm4QsO0bR6T1I6xA+Ohkjnv4aO2pRaG/WxQSrCiEtZM5ecxeu5spiSmsSj1EpfLluLJzE0YmxNKlWW2/7lWk7D/GPdNWszL1EEM7N+HpYR0CWpzMqaZ9n8qDH61jXL82jAnzfoQViDMoKAqfrdvD/E17OZ6dR91CewpWFCLThl2HeS8xlU9XpXEsO4/20TUZ2SuWYV2aUr0ML9Gpqrz//Q6enr2R8uWEp4d3YFiXpmX2/ubsqCrjpq9hxuo03v19Qlj3I6xAnMGEeVt4ZcE26larSP/zGjOkkxUF87OjWbl8uiqNd5elsHlPJtUqRjG8a1NGJjSnfZNfN1NqeuZJHv5oHfM3p3NBq/o8f00nomuFzum34a6gH3HkRC5zxl4QtgMSrUCcwY4Dx0nZf5xe51hRMKenqqza4UwWOHvtLrJy8+kWW5uRCc0Z3Cm61E3kLzbs4eGP13EsK5eHB7bl5t5xQX26baTavMfpR3RvXod3fpcQlv2IoCgQIrIdyATygFxVjReRusA0IA7YDlyrqgfFOdj7MjAIOA7cqqorz/T+Xg+UM5Hj0PFsPlrpTBaYnHGMWlUqMKK7M1lgywbVz/jazJM5PDVrIx+s2EmHpjV56boutGoYORMMhqLp3+/ggY/Wcs/lbRh7efj1I4KpQMSr6r5Cy54DDqjqeBF5CKijqg+KyCBgNE6BSABeVtWEM72/FQgTaKrKd8n7mZKYyhfr95Cbr/Q+px4je8VyRfvGVCx/6h7p8p8OMG76anYdOsGdl7Zi9GWtf7GOCT6qyr3T1/DJ6jSm3J7A+a3Cqx8RzAViC3CJqu4WkWhgkaqeKyJvuPenFl3vdO9vBcJ4KT3zJB8k7eS9xFTSDp2gfvVKXNcjhut7xNKwZiUmfPkDkxYnE1u3KhOu7UL35nW8jmxK4VhWLkNfXcrhMOxHBEuB+Ak4CCjwhqpOEpFDqlrbfV6Ag6paW0RmA+NVdan73HzgQVVNKvKeo4BRALGxsd1TUlL8lt8YX+TlK4u3ZjBlWSoLNu9FgYY1KrH3SBY3JsTy6KB2VCvDs6BM4GzZk8mw15bSLbYO/709fPoRwTLVxgWqmiYiDYEvRWRz4SdVVUWkVBVKVScBk8DZgyi7qMacnahywqXnNuTScxuSdugE05an8v32gzzzm45c1raR1/HMr3Bu4xo8NawDD3y4lokLtnL35W28jhRQfi0Qqprmfk0XkU+AnsBeEYkudIgp3V09DWhW6OUx7jJjQkbT2lUYd8W5XscwZeia7jEsS97Py/O30iOuLn3CrB9xJn7rlolINRGpUXAfuAJYD8wEbnFXuwWY4d6fCdwsjl7A4TP1H4wxJhBEhL8M70DLBtUZ+/5q0jNPeh0pYPx5OkUjYKmIrAGWA5+p6lxgPNBPRLYCl7uPAeYAycA24E3gDj9mM8YYn1WtWJ7XbuzG0awcxk5dTV5+ZBzdjsiBcsYYczY+SNrB/R+uZUzf1ozrF7r9CF+b1HZCtjHG+Oia+GZc3S2GiQu2snTrvpJfEOKsQBhjTCk8Pfw8WjWozt3TVpF+JLz7EVYgjDGmFKpWLM/rI7txLCuPMe+vCut+hBUIY4wppdaNavD08A4sSz7Ay1/94HUcv7ECYYwxZ2FE9xhGdI9h4sJtLNma4XUcv7ACYYwxZ+mpYW4/4v3V7A3DfoQVCGOMOUsF/Yjj2XmMmbqK3Lx8ryOVKSsQxhjzK7RuVIO/DO9A4k8HeHn+Vq/jlCkrEMYY8ytd3T2Ga7rH8OrCbSz+IXz6EVYgjDGmDDw1rAOtG1bnnmnh04+wAmGMMWWgSsWosOtHWIEwxpgy0qrhz/2Il74K/X6EFQhjjClDV3eP4dr4GF5btI2vQ7wfYQXCGGPK2JNDO9CmYQ3umbaaPYdDtx9hBcIYY8pYlYpRvDayGydznPmaQrUfYQXCGGP8oFXD6vz1qg4s/+kAL4bofE1WIIwxxk+u6hrDdfHNeG3hjyHZj7ACYYwxfvTE0PM4t1Fo9iOsQBhjjB+d0o8IsfERViCMMcbPWjWszt+u6sjy7QeY8GXo9CP8XiBEJEpEVonIbPdxCxFJFJFtIjJNRCq6yyu5j7e5z8f5O5sxxgTK8K5Nub5HM15f9COLtqR7HccngdiDGAtsKvT4WeBFVW0FHARud5ffDhx0l7/ormeMMWHjiaHn0bZxDcZNX8Puwye8jlMivxYIEYkBBgP/ch8LcBnwobvKZGC4e3+Y+xj3+b7u+saYcJZ1FBY9C5l7vU7id5UrhFY/wqcCISINROQREZkkIm8X3Hx46UvAA0DBp1APOKSque7jnUBT935TYAeA+/xhd/2iWUaJSJKIJGVkhN5pY8aYIr56Ahb9DWbeBapep/G7lg2cfsT32w/yQpD3I3zdg5gB1AK+Aj4rdDstERkCpKvqil+VsAhVnaSq8aoa36BBg7J8a2NMoKV8C9+/CfXPha3zYO10rxMFxPCuTbmhZzP+sehHFgZxP8LXAlFVVR9U1emq+lHBrYTX9AGGish24H2cQ0svA7VFpLy7TgyQ5t5PA5oBuM/XAvb7/q0YY0JKzgmYcRfUjoU/zIeYnjD3QTgaGUcGHr/S7UdMWx20/QhfC8RsERlUmjdW1YdVNUZV44DrgQWqOhJYCIxwV7sFZ+8EYKb7GPf5BaoRsL9pTKRaNB4O/AhXvgKVasCwVyH7GHx+v9fJAqKgH5Gdm8/o91aRE4T9CF8LxFicInFSRDLd25Gz3OaDwDgR2YbTY3jLXf4WUM9dPg546Czf3xgT7Hatgm8nQtffQstLnWUNzoWLH4ANn8Cm2d7mC5CWDarzt990JCnlIC/MC75+hITyH+nx8fGalJTkdQxjTGnkZsObl8Lx/XDHMqhS++fn8nKc546mw52JUKWOdzkD6OGP1zF1eSr/vrUHl7Zt6PfticgKVY0vaT2fT3MVkaEi8nf3NuTXxTPGRKxvXoK962HwhFOLA0BUBRj6KhzbB1/8yZt8Hnj8yva0i67JuOmr2XUoePoRvp7mOh7nMNNG9zZWRJ7xZzBjTBhK3wxfPwfn/Qbanqat2aQL9BkDq9+FHxcENp9HKleI4rUbuzr9iKnB04/wdQ9iENBPVd9W1beBATgD4Iwxxjf5eTDjTqchPej5M6978UNQrzXMHOsMpIsA57j9iBUpB/n7vC1exwFKN5K68L5grbIOYowJc4n/hLQkGPgcVKt/5nUrVHbOajq8A+Y/FZh8QWBYl6bcmBDLG18ns2Cz9yPLfS0QzwCrROQ/IjIZWAH81X+xjDFh5UAyzH8a2gyAjiNKXh8gthf0HAXLJ0HqMv/mCyJ/HlLQj1jjeT/CpwKhqlOBXsDHwEdAb1Wd5s9gxpgwoQozxzgN6METoDRTrPX9M9Rq5gyoywmti+2crcoVonh9ZDdycvO5672VnvYjzlggRKSt+7UbEI0zd9JOoIm7zBhjzmzlZNi+BPo9BbWalrx+YZWqw5Uvwf6t8HXkTPDcon41nrm6EytTD/H3L7zrR5Qv4flxwCjghWKeU5zpM4wxpniH02DeYxB3IXS/9ezeo1Vf6HITfPMytB/mnOUUAYZ2bkJi8n7eWJxMzxZ16duuUcAznHEPQlVHuXcHquqlhW84ZzYZY0zxVOGzcc7gt6GvlO7QUlH9/+I0tmfe5bxfhHhsSHvaR9fk3g/WkOZBP8LXJvW3Pi4zxhjHug/hh7nQ9zGoe86ve68qdZz+xZ51zkC7CFEwX1NunnrSjyipB9FYRLoDVUSkq4h0c2+XAFUDktAYE3qO7YPPH4Cm8ZDwf2Xznu2GQPvhzkC7jOAYJxAILepXY/zVHVmVeojnA9yPKKkH0R+4FWda7gmFlmcCj/gpkzEm1H3+AGRlOmMZykWV3fsOeh5++to5q+l3c8v2vYPYkE5NSEw+wKTFyfSMq8vl7QPTjyipBzHZ7TfcWqQHMVRVPw5IQmNMaNk8B9Z/5MzM2rBd2b539YYw4FnYudwZHxFBHh3cjvOaOP2InQePB2Sbvo6D+EhEBovIAyLy54Kbv8MZY0LMiUMw+x5o1AEuuMc/2+h0LbS+whlhfeAn/2wjCDnzNXUjL1+5671VZOf6vx/h62R9/wSuA0YDAlwDNPdjLmNMKPryMTiW4Rxaiqrgn22IwJAXQaJg1tiIuI51gbj61Xj26k6s3nGIt7/xf3H09Sym81X1ZuCgqj4J9Aba+C+WMSbkJC+Cle/A+aOhSVf/bqtWDPR70ulHrPqvf7cVZAZ3iubl67twS+84v2/L1wJRMMb9uIg0AXJwRlYbY4xzqdCZY6BuS7gkQBeD7H4bNL/AuW7Ekd2B2WaQGNalKVUq+r9B72uBmCUitYHngZXAduA9f4UyxoSY+U/DoRTn0FKFKoHZZrlyzgC8vGxnQF4EHWoKlBILhIiUA+ar6iFV/Qin99BWVa1JbYyB1ERnKu8ef4Dm5wd22/VawmWPwhb3zClTpkosEKqaD7xW6HGWqh72aypjTGjIOelMf1ErBi5/3JsMve6Apt2dsRfH9nuTIUz5eohpvohcLeL7ZCoiUllElovIGhHZICJPustbiEiiiGwTkWkiUtFdXsl9vM19Pq7U340xJrAWPw/7fnBmXK1Uw5sM5aKc61ifPAJzH/QmQ5jytUD8EfgAyBKRIyKSKSJHSnhNFnCZqnYGugADRKQX8Czwoqq2Ag4Ct7vr345zllQr4EV3PWNMsNq9Fpa+CJ1vhFaXe5ulUXu46D5Y9wFsmettljDi60C5GqpaTlUrqmpN93HNEl6jqlpwMdkK7q1givAP3eWTgeHu/WHuY9zn+5azyFkZAAAWPklEQVRmj8UYE0B5Oc71pavWg/5BcnHJC8ZBw/OcgXon7Sh4WfB1oNxFxd18eF2UiKwG0oEvgR+BQ6qa666yEyi4gkhTYAeA+/xhoF4x7zlKRJJEJCkjI8OX+MaYsvbtRNizFga/AFXrep3GUb4iDJsIR/c416Awv1pJk/UVuL/Q/cpAT5zrUp/xgkGqmgd0cU+R/QRoezYhi7znJGASQHx8vJ3XZkyg7dsKi8Y7F+9pP9TrNKdq2h163+kUsA5XwzkXe50opPl6iOnKQrd+QAec/oFPVPUQsBBnBHZtESkoTDFAmns/DWgG4D5fC7BTEowJJvn5zkyqFarAwOe9TlO8Sx5xrj8xa4wzgM+cNV+b1EXtBM44TaOINHD3HBCRKkA/YBNOoRjhrnYLMMO9P9N9jPv8AlUb+WJMUPn+TdixDAaMhxqBvwSmTypWdc5qOrgdFgRJfyRE+XSISUQm4jSYwSkqXXBGVJ9JNDBZRKLc10xX1dkishF4X0T+AqwC3nLXfwv4r4hsAw4A15fqOzHG+NfBFPjqSeeMpc5B/uMZ1wfib4dlr8N5V0GzHl4nCkniyx/pInJLoYe5wHZV/cZvqXwUHx+vSUlJXscwJvypwn+vgp3fwx3LoHYzrxOV7OQReL03VKoOf1wM5St5nShoiMgKVY0vaT1fexCTgTnAHFWdEgzFwRgTQKunQPJCZwbVUCgOAJVrOgP4MjbD4r97nSYklXRNahGRJ0RkH7AF+EFEMuxiQcZEkMw98MUj0LwPdP+d12lKp3U/6HQ9LJ0Ae9Z5nSbklLQHcQ/QB+ihqnVVtQ6QAPQRET9dLsoYEzRU4bN7ITcLhk50ZlANNQOegSp1nLOv8nJLXt/8T0n/2r8FblDV/126SFWTgZuAm/0ZzBgTBDZ+Cptnw6WPODOnhqKqdWHQ32H3avhuotdpQkpJBaKCqu4rulBVM3CmzjDGhKvjB2DO/c7V4Xrd6XWaX6f9MGg7BBY+A/u2eZ0mZJRUILLP8jljTKib+xCcOAjDXoMoXyddCFIizrQgFSo705Pn53udKCSUVCA6u7O3Fr1lAh0DEdAY44Ef5sHaaXDhvdDoPK/TlI0ajaH/M5D6HSS9VfL65swFQlWj3Nlbi95qqKodYjImHJ08ArPvhgbt4ML7vE5TtrrcCC37wldPwKFUr9MEvRA8JcEY41dfPQ6Zu51DS+Urep2mbIk4YyNUYdZYu451CaxAGGN+9tMSSHrbuYxnTHev0/hH7Vi4/An4cQGsmep1mqBmBcIY48g+DjNHQ50WcOmjXqfxrx6/h9jeMPdhyNzrdZqgZQXCGONY+Fc4+JMzIK5iVa/T+Fe5cs73mXMC5tzrdZqgZQXCGAM7Vzgzn3a/DVpc6HWawKjfGi59GDbNgg2fep0mKFmBMCbS5WY7YwNqREO/p7xOE1i9R0N0Z5hznzMw0JzCCoQxkW7JC5C+EYa86MyAGkmiyjtna5046ExIaE5hBcKYSLZ3Ayz5O3S8Ftr09zqNNxp3hAvucc5o2vql12mCihUIYyJVXi7MuBMq13YuIRrJLrofGrSFWXc7AwUNYAXCmMi17HXYtQoGPQ/V6nmdxlvlKznXsT6S5oyyNoAVCGMi0/4fndNa2w5xrtlsnOtW9/p/zjxN2+2imWAFwpjIk5/vDIiLquTMcCridaLgcdmfoE6c8/nknPA6jef8ViBEpJmILBSRjSKyQUTGusvrisiXIrLV/VrHXS4i8oqIbBORtSLSzV/ZjIloK96GlG+g/1+dGU7NzypWgytfgQM/wsK/eZ3Gc/7cg8gF7lXV9kAv4E4RaQ88BMxX1dbAfPcxwECgtXsbBfzDj9mMiUyHdsCXj8M5l0LXm7xOE5zOuRi63QLfvQppK7xO4ym/FQhV3a2qK937mcAmoCkwDJjsrjYZGO7eHwa8o45lQG0RifZXPmMijirMvsf5euXLdmjpTK54Gqo3ghmjnYGEESogPQgRiQO6AolAI1Xd7T61B2jk3m8K7Cj0sp3uMmNMWVg7DbZ9CZc/DnWae50muFWu5QwcTN8AS1/0Oo1n/F4gRKQ68BFwt6qecoKxqipQqgnZRWSUiCSJSFJGRkYZJjUmjB1Ndy4h2qwX9PiD12lCw7kDocMIWPw87N3odRpP+LVAiEgFnOIwRVU/dhfvLTh05H5Nd5enAc0KvTzGXXYKVZ2kqvGqGt+gQQP/hTcmnMy5z5nOe+hEZyZT45uBzzrTj8y8C/LzvE4TcP48i0mAt4BNqjqh0FMzgVvc+7cAMwotv9k9m6kXcLjQoShjzNnaOBM2zoBLHoQGbbxOE1qq1YeBzznN6mWve50m4Pz5p0Qf4LfAZSKy2r0NAsYD/URkK3C5+xhgDpAMbAPeBO7wYzZjIsOJg87eQ+NOcP4Yr9OEpg5XQ5uBsOCvzgDDCFLeX2+sqkuB050m0beY9RW40195jIlIXzwKx/fDyA8hqoLXaUKTCAyZAK8lONexvnlmxBymi4zv0phItO0rWD0F+twN0Z28ThPaajaBK/4C25fAyv94nSZgrEAYE46yMp2ZSeu3cWYqNb9et5uhxcUw789weKfXaQLCCoQx4Wj+U84vsWGvQYXKXqcJDyLOAEPN+3nAYZizAmFMuEn5DpZPgoT/g2Y9vU4TXuq2gMseg63zYN0HXqfxOysQxoSTnBPOOfu1Y6HvY16nCU8Jf4SYnvD5g3A0vAfrWoEwJpwsGg/7tzkzklas5nWa8FQuCoa9CtlH4fPw7u9YgTAmXOxaBd9OhK6/hZaXep0mvDU4Fy5+ADZ8Aptme53Gb6xAGBMO8nKcmUerN3ROxzT+1+duaNQRPhvnDEgMQ1YgjAkHS1+Cvetg8ASoUtvrNJEhqoJzqOnYPpj3J6/T+IUVCGNCXfpmWPycMyVE20Fep4ksTbpAnzGw6l34cYHXacqcFQhjQll+Hsy4EypWdyaVM4F38UNQrzXMHAtZR71OU6asQBgTyhLfgLQkpzhUq+91mshUobJzqOnwDmeAYhixAmFMqDrwEyx4GtoMgI4jvE4T2WJ7Qc8/OAMUU5d5nabMWIEwJhSpwqwxUK68c2lMu7609/o+DrWawYy7IOek12nKhBUIY0LRysnw02K44mlnplHjvUrV4cqXYP9W+PpZr9OUCSsQxoSaI7tg3mMQdyF0u6Xk9U3gtOoLXW6Cb16GXau9TvOrWYEwJpSowuxxzsC4oa/YoaVg1P8vzgkDM+9y/p1CmBUIY0LJ+o/gh8+difjqnuN1GlOcKnVg8AuwZ52zJxHCrEAYEyqO7YPPH4CYHs5U3iZ4tbsS2g93ehEZW7xOc9asQBgTKj5/wLlS3NBXnRlFTXAb9Lwzo+6Mu5wBjSHICoQxoWDzHOfw0kX3Q8O2XqcxvqjeEAY8CzuXO+MjQpDfCoSIvC0i6SKyvtCyuiLypYhsdb/WcZeLiLwiIttEZK2IdPNXLmNCzolDzoyhjTrABfd4ncaURqdroVU/Z4T1we1epyk1f+5B/AcYUGTZQ8B8VW0NzHcfAwwEWru3UcA//JjLmNDy5WNwNN2ZziGqgtdpTGmIOGMjJApmjQ2561j7rUCo6mLgQJHFw4DJ7v3JwPBCy99RxzKgtohE+yubMSEjeRGsfAfOHw1NunqdxpyNWjHQ70nn33LVf71OUyqB7kE0UtXd7v09QCP3flNgR6H1drrLfkFERolIkogkZWSE9/VgTYTLPgYzx0C9VnDJQyWvb4JX99ug+QXwxZ/gyO6S1w8SnjWpVVWBUu9vqeokVY1X1fgGDRr4IZkxQWLBX+BQCgydCBWqeJ3G/BrlyjkDG/OynH5SiBxqCnSB2Ftw6Mj9mu4uTwOaFVovxl1mTGTasRyW/QN6/AGan+91GlMW6rWESx+FLXNgw8dep/FJoAvETKBg8phbgBmFlt/sns3UCzhc6FCUMZElN8s5d75WDFz+uNdpTFnqdQc06QZzHoBj+71OUyJ/nuY6FfgOOFdEdorI7cB4oJ+IbAUudx8DzAGSgW3Am8Ad/splTND7+jnYt8U5+6VSDa/TmLIUVR6GvQYnD8PcB71OU6Ly/npjVb3hNE/1LWZdBe70VxZjQsbutfDNS9D5Rmh1uddpjD80ag8X3QeLnoEOI+DcoqMBgoeNpDYmWOTlOjOAVqkL/f/qdRrjTxeMg4btYfY9zt5EkLICYUyw+PYV2L3GmQm0al2v0xh/Kl/RGfh4dA98+Wev05yWFQhjgsG+rbBoPLQfBu2Hep3GBELT7tD7TljxH+fqgEHICoQxXsvPd85aqlAFBv3d6zQmkC55xLmux8zRzsDIIGMFwhivff8v2LEMBox3ZgA1kaNiVWcg5MHtsCD4+k5WIIzx0sEU+OoJ54ylztd7ncZ4Ie4CiP8dLHsddnzvdZpTWIEwxiuqzgyfIjDkJbu+dCS7/Emo2dQ5iy03y+s0/2MFwhivrJ4CyQudmT5rNyt5fRO+Ktd0BkZmbIbFwdOHsgJhjBcy98AXj0DzPtD9d16nMcGgdT/odD0snQB71nmdBrACYUzgqcJn9zqHEoZOdGb6NAZgwDNQpY5zVltertdprEAYE3AbP4XNs+HSR5wZPo0pULUuDHoedq+G7171Oo0VCGMC6vgBmHO/c3W4Xjb9mClG++HQdogzV9O+bZ5GsQJhTCDNfRhOHHJm9Izy21yZJpSJONOtlK/knNWUn+9ZFCsQxgTKD/Ng7ftw4b3Q6Dyv05hgVqMx9H8GUr+DpLc8i2EFwphAOHkEZt8NDdo5BcKYknS5EVpe5gykPJTqSQQrEMYEwlePQ+Zu59BS+YpepzGhoGAApSrMutuT61hbgTDG335aAklvO5ebjOnudRoTSuo0h8ufgB/nw5qpAd+8FQhj/Cn7OMwaA3VaOBesN6a0evweYns7Jzhk7g3opq1AGONPi/4GB5KdAXEVq3qdxoSicuWc/z85J2BOYPtXViCM8Ze0FfDda9D9NmhxoddpTCir3xoueQg2zYKNMwK22aAqECIyQES2iMg2EXnI6zzGnLXcbGe6hBrR0O8pr9OYcHD+GIjuDJ/d5wy4DICgKRAiEgW8BgwE2gM3iEh7b1MZc5aWToD0jc5ZKJVrep3GhIOo8s5ZcCcOOBM9BkAwDeXsCWxT1WQAEXkfGAZsLOsNPTv7VjanryrrtzXmZzknoFUHSJ7q3IwpK206w975tJ13Bw9e8bpfNxVMBaIpsKPQ451AQtGVRGQUMAogNjb27LZUoTJUsIah8aNKNaFOnNcpTDiq1QyyjkE5///6DqYC4RNVnQRMAoiPjz+rkSMP9v9nmWYyxphwFDQ9CCANKHxZrRh3mTHGGA8EU4H4HmgtIi1EpCJwPTDT40zGGBOxguYQk6rmishdwBdAFPC2qm7wOJYxxkSsoCkQAKo6B5jjdQ5jjDHBdYjJGGNMELECYYwxplhWIIwxxhTLCoQxxphiiXpwlaKyIiIZQMpZvrw+sK8M45QVy1U6lqv0gjWb5SqdX5Oruao2KGmlkC4Qv4aIJKlqvNc5irJcpWO5Si9Ys1mu0glELjvEZIwxplhWIIwxxhQrkgvEJK8DnIblKh3LVXrBms1ylY7fc0VsD8IYY8yZRfIehDHGmDOwAmGMMaZYYV8gRGSAiGwRkW0i8lAxz1cSkWnu84kiEhckuW4VkQwRWe3efh+gXG+LSLqIrD/N8yIir7i514pItyDJdYmIHC70ef05AJmaichCEdkoIhtEZGwx6wT88/IxlxefV2URWS4ia9xcTxazTsB/Hn3M5cnPo7vtKBFZJSKzi3nOv5+XqobtDWfa8B+Bc4CKwBqgfZF17gD+6d6/HpgWJLluBV714DO7COgGrD/N84OAzwEBegGJQZLrEmB2gD+raKCbe78G8EMx/44B/7x8zOXF5yVAdfd+BSAR6FVkHS9+Hn3J5cnPo7vtccB7xf17+fvzCvc9iJ7ANlVNVtVs4H1gWJF1hgGT3fsfAn1FRIIglydUdTFw4AyrDAPeUccyoLaIRAdBroBT1d2qutK9nwlswrm2emEB/7x8zBVw7mdw1H1Ywb0VPUsm4D+PPubyhIjEAIOBf51mFb9+XuFeIJoCOwo93skvf1D+t46q5gKHgXpBkAvgavewxIci0qyY573ga3Yv9HYPE3wuIucFcsPurn1XnL8+C/P08zpDLvDg83IPl6wG0oEvVfW0n1cAfx59yQXe/Dy+BDwA5J/meb9+XuFeIELZLCBOVTsBX/LzXwmmeCtx5pfpDEwEPg3UhkWkOvARcLeqHgnUdktSQi5PPi9VzVPVLjjXnO8pIh0Csd2S+JAr4D+PIjIESFfVFf7e1umEe4FIAwpX+hh3WbHriEh5oBaw3+tcqrpfVbPch/8Cuvs5k698+UwDTlWPFBwmUOfKhBVEpL6/tysiFXB+CU9R1Y+LWcWTz6ukXF59XoW2fwhYCAwo8pQXP48l5vLo57EPMFREtuMchr5MRN4tso5fP69wLxDfA61FpIWIVMRp4swsss5M4Bb3/ghggbodHy9zFTlOPRTnOHIwmAnc7J6d0ws4rKq7vQ4lIo0Ljr2KSE+c/9t+/cXibu8tYJOqTjjNagH/vHzJ5dHn1UBEarv3qwD9gM1FVgv4z6Mvubz4eVTVh1U1RlXjcH5HLFDVm4qs5tfPK6iuSV3WVDVXRO4CvsA5c+htVd0gIk8BSao6E+cH6b8isg2nCXp9kOQaIyJDgVw3163+zgUgIlNxznCpLyI7gcdxmnao6j9xrhk+CNgGHAduC5JcI4D/JyK5wAng+gAU+j7Ab4F17vFrgEeA2EK5vPi8fMnlxecVDUwWkSicgjRdVWd7/fPoYy5Pfh6LE8jPy6baMMYYU6xwP8RkjDHmLFmBMMYYUywrEMYYY4plBcIYY0yxrEAYY4wplhUIYwoRkbxCM3aulmJm2i2y/v+JyM1lsN3tgRyoZowv7DRXYwoRkaOqWt2D7W4H4lV1X6C3bczp2B6EMT5w/8J/TkTWiXPtgFbu8idE5D73/hhxrsGwVkTed5fVFZFP3WXLRKSTu7yeiMwT5/oD/8KZcrpgWze521gtIm+4A7iMCTgrEMacqkqRQ0zXFXrusKp2BF7FmWWzqIeAru6Ebv/nLnsSWOUuewR4x13+OLBUVc8DPsEd5Swi7YDrgD7u5HF5wMiy/RaN8U1YT7VhzFk44f5iLs7UQl9fLOb5tcAUEfmUn2dHvQC4GkBVF7h7DjVxLoD0G3f5ZyJy0F2/L85EcN+7UyVVwZmC2piAswJhjO/0NPcLDMb5xX8l8KiIdDyLbQgwWVUfPovXGlOm7BCTMb67rtDX7wo/ISLlgGaquhB4EGfa5erAEtxDRCJyCbDPvTbDYuBGd/lAoI77VvOBESLS0H2urog09+P3ZMxp2R6EMaeqUmgGVIC5qlpwqmsdEVkLZAE3FHldFPCuiNTC2Qt4RVUPicgTwNvu647z89TMTwJTRWQD8C2QCqCqG0XkT8A8t+jkAHcCKWX9jRpTEjvN1Rgf2GmoJhLZISZjjDHFsj0IY4wxxbI9CGOMMcWyAmGMMaZYViCMMcYUywqEMcaYYlmBMMYYU6z/DxfZqsTCI+5KAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing\n",
    "train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-c787c6f6d1d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m68\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{load_net_prefix}{idx}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-5d94ea740ebb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_episodes, human)\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;31m# Perform one step of the optimization (on the target network)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwarmup\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mTRAIN_RATE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                     \u001b[0moptimize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0mepisode_durations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-04814b0e198f>\u001b[0m in \u001b[0;36moptimize_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtransitions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5f994df79252>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/random.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    338\u001b[0m                     \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0mselected_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "idx = 68\n",
    "while True:\n",
    "    train(15000)\n",
    "    torch.save(policy_net, f'{load_net_prefix}{idx}')\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(policy_net, f'{load_net_prefix}{idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_func = lambda e: policy_net.eval()(get_screen(e.get_grid())).max(1)[1].view(1, 1).squeeze().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tetris.Tetris import watch_bot_tetris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".  .  .  .  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .  .  .  .\n",
      ".  .  .  .  .  .  .  .  .  .\n",
      ".  O  O  .  .  .  .  .  .  .\n",
      ".  O  O  .  O  O  .  .  .  .\n",
      ".  .  .  .  O  O  .  .  .  .\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b24aece899b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwatch_bot_tetris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpieces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Programs/Tetris/tetris/Tetris.py\u001b[0m in \u001b[0;36mwatch_bot_tetris\u001b[0;34m(action_function, turn_time, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mturn_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "watch_bot_tetris(action_func, pieces=[O])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of DQN(\n",
       "  (shared_layers): Sequential(\n",
       "    (0): Linear(in_features=200, out_features=400, bias=True)\n",
       "    (1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=400, out_features=1200, bias=True)\n",
       "    (4): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): NoisyFactorizedLinear(in_features=1200, out_features=400, bias=True)\n",
       "    (7): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "  )\n",
       "  (value_layer1): Linear(in_features=400, out_features=256, bias=True)\n",
       "  (vbn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (value_layer2): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (advantage_layer1): NoisyFactorizedLinear(in_features=400, out_features=256, bias=True)\n",
       "  (abn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (advantage_layer2): NoisyFactorizedLinear(in_features=256, out_features=7, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_net.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "curses.endwin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscr.addstr(\"Test\\nTest\\nTest\\n\")\n",
    "stdscr.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gym.envs.classic_control.rendering.SimpleImageViewer object at 0x7fb555b6e160>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ae85c8d89772>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwatch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-abb458bb53ea>\u001b[0m in \u001b[0;36mwatch_model\u001b[0;34m(rounds)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwatch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhuman\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-abb458bb53ea>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_episodes, human)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;31m# Observe new state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_screen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhuman\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhuman\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-451a7ae40841>\u001b[0m in \u001b[0;36mget_screen\u001b[0;34m(screen, human)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhuman\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mbla\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mscreen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Turn greyscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym_tetris/tetris_env.py\u001b[0m in \u001b[0;36mscreen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;34m\"\"\"Return the screen of the game\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym_tetris/tetris.py\u001b[0m in \u001b[0;36mscreen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;34m\"\"\"Return the screen as a NumPy array.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurfarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_screen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pygame/surfarray.py\u001b[0m in \u001b[0;36marray3d\u001b[0;34m(surface)\u001b[0m\n\u001b[1;32m    127\u001b[0m     method).\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnumpysf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray3d\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msurface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpixels3d\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msurface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pygame/_numpysurfarray.py\u001b[0m in \u001b[0;36marray3d\u001b[0;34m(surface)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msurface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0msurface_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "watch_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0765313099202285"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_eps(steps_done)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
