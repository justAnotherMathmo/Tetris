{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tetris Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.4\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import gym_tetris\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym_tetris.make('Tetris-v0')\n",
    "BATCH_SIZE = 196\n",
    "GAMMA = 0.9\n",
    "MULISTEP_GAMMA = 0.98\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.01\n",
    "EPS_DECAY = 50000000\n",
    "TARGET_UPDATE = 50\n",
    "NUM_STATES = env.action_space.n\n",
    "MULTISTEP_PARAM = 5\n",
    "MOVEMENT_COST = 0.01\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "def curr_eps(steps):\n",
    "    return EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps / EPS_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.bias = []\n",
    "        self.bias_sum = 0\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args, bias=1):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "            self.bias.append(None)\n",
    "            self.bias_sum += bias\n",
    "        else:\n",
    "            # Don't add if small bias\n",
    "            if bias < self.bias_sum / len(self.memory) * (curr_eps(steps_done) - EPS_END):\n",
    "                return\n",
    "            self.bias_sum -= self.bias[self.position]\n",
    "            self.bias_sum += bias\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.bias[self.position] = bias\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size, biased=True):\n",
    "        if biased:\n",
    "            choice_indices = np.random.choice(len(self.memory), size=batch_size, replace=False, p=np.array(self.bias) / self.bias_sum)\n",
    "            return [self.memory[i] for i in choice_indices]\n",
    "        else:\n",
    "            return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I figure, if we've abstracted away the problem, we can get rid of the convolutional \n",
    "#  layers and make it fully dense...\n",
    "# Will add those in later when we can get the toy model to work, I guess\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, h, w):\n",
    "        super(DQN, self).__init__()\n",
    "        self.input_layer_width = h * w\n",
    "        self.fc1 = nn.Linear(self.input_layer_width, self.input_layer_width * 3)\n",
    "        self.fc2 = nn.Linear(self.input_layer_width * 3, self.input_layer_width * 8)\n",
    "        self.fc3 = nn.Linear(self.input_layer_width * 8, self.input_layer_width * 3)\n",
    "        self.fc4 = nn.Linear(self.input_layer_width * 3, self.input_layer_width)\n",
    "        self.output_layer = nn.Linear(self.input_layer_width, 12)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x.view(x.size(0), -1)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_state(state_var):\n",
    "    \"\"\"Returns a greyscale image with pixels taking values in [0,1]. Also adds a batch dimension\"\"\"\n",
    "    greyscale  = np.sum(state_var, axis=2) / (3 * 255)\n",
    "    return greyscale\n",
    "\n",
    "def compress_board(state):\n",
    "    \"\"\"Assumes board greyscale\"\"\"\n",
    "    small_board = state[10:423:20, 20:213:20]\n",
    "    next_piece = state[180:241:20, 235:296:20]\n",
    "    return small_board, next_piece\n",
    "\n",
    "def combine_board_and_piece(board, piece):\n",
    "    return board\n",
    "\n",
    "def get_screen(screen=None, human=False):\n",
    "    if screen is None and not human:\n",
    "        screen = env.render(mode='rgb_array')\n",
    "    if human:\n",
    "        bla = env.render()\n",
    "        screen = env.env.screen\n",
    "        \n",
    "    # Turn greyscale\n",
    "    screen = clean_state(screen)\n",
    "    \n",
    "    # Compress\n",
    "    screen, piece = compress_board(screen)\n",
    "    screen = combine_board_and_piece(screen, piece)\n",
    "    \n",
    "    # Resize and add a batch dimension (BCHW)\n",
    "    tensor = torch.from_numpy(screen).unsqueeze(0).unsqueeze(0)\n",
    "    # Push to floats on GPU\n",
    "    return tensor.type(torch.FloatTensor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fell back to creating a new net...\n"
     ]
    }
   ],
   "source": [
    "load_net_prefix = './models/tetrisBot6v'\n",
    "load_net_number = 0\n",
    "net_to_load = f'{load_net_prefix}{load_net_number}'\n",
    "try:\n",
    "    policy_net = torch.load(net_to_load)\n",
    "    policy_net.eval()\n",
    "    target_net = torch.load(net_to_load)\n",
    "    target_net.eval()\n",
    "    print(f'{net_to_load} loaded...')\n",
    "except:\n",
    "    policy_net = DQN(screen_height, screen_width).to(device)\n",
    "    target_net = DQN(screen_height, screen_width).to(device)\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    target_net.eval()\n",
    "    print(f'Fell back to creating a new net...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(policy_net.parameters(), lr=10**-4)\n",
    "memory = ReplayMemory(100000)\n",
    "\n",
    "def select_action(state, deterministic=False):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = curr_eps(steps_done)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold and not deterministic:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(NUM_STATES)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "lines_cleared = []\n",
    "\n",
    "def plot_durations(save=None):\n",
    "    fig = plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    plt.plot(np.array(lines_cleared) * 200)\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    \n",
    "    if save is not None:\n",
    "        fig.savefig(save, bbox_inches='tight')\n",
    "        \n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "#         display.display(plt.gcf())\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_single(state, action, next_state, reward):\n",
    "    return _compute_loss(state, action, next_state, reward, batch_size=1)\n",
    "\n",
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE, biased=False)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    next_state_batch = torch.cat(batch.next_state)\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Huber loss\n",
    "    loss = _compute_loss(state_batch, action_batch, next_state_batch, reward_batch)\n",
    "    \n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n",
    "\n",
    "def _compute_loss(_state, _action, _next_state, _reward, batch_size=BATCH_SIZE):\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(_state).gather(1, _action)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "#     next_state_values = target_net(_next_state).max(1)[0].detach()\n",
    "    \n",
    "#     Double Q learning:\n",
    "    next_state_values = target_net(get_screen())[0][policy_net(get_screen()).argmax(1)[0]].detach()\n",
    "    \n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + _reward\n",
    "\n",
    "    # Compute Huber loss\n",
    "    return F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def did_piece_fall(env):\n",
    "    return (env.unwrapped.game.falling_piece is None)\n",
    "\n",
    "def create_reward(this_env, block_placed, action, is_done, info,\n",
    "                  old_height, old_lines, hole_count=0, hole_towers=0,\n",
    "                  include_height=True, include_score=True, include_holes=True, include_towers=True):\n",
    "    \"\"\"Assumes states are 21 x 10\"\"\"\n",
    "    if not block_placed:\n",
    "        # Punish a little for doing something that isn't the empty move\n",
    "        if action == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return -MOVEMENT_COST\n",
    "    if is_done:\n",
    "        return -50.0\n",
    "    \n",
    "    total_reward = 0\n",
    "    if include_height:\n",
    "        if info['height'] > old_height: \n",
    "            # Punish a little more the closer you are to the top\n",
    "            total_reward += (1 + info['height'] / 10) * (old_height - info['height']) /3\n",
    "    \n",
    "    line_diff = this_env.unwrapped.game.complete_lines - old_lines\n",
    "    if include_score and line_diff != 0:\n",
    "        total_reward += 20 * 2 ** (line_diff)\n",
    "    \n",
    "    if include_holes:\n",
    "        total_reward -= hole_count * 1.5\n",
    "    if include_towers:\n",
    "        total_reward -= include_towers\n",
    "    \n",
    "    return total_reward\n",
    "\n",
    "def num_holes(state):\n",
    "    flat_state = np.where(state.cpu() > 0, 1, 0).squeeze(0).squeeze(0)\n",
    "    return np.sum(np.where((np.roll(flat_state, flat_state.shape[1]) > 0) & (flat_state == 0), 1, 0)[1:, :])\n",
    "\n",
    "def num_holy_towers(state):\n",
    "    \"\"\"This is a fucking work of art\"\"\"\n",
    "    flat_state = np.where(state.cpu() > 0, 1, 0).squeeze(0).squeeze(0)\n",
    "    mask = np.where((np.roll(flat_state, flat_state.shape[1]) > 0) & (flat_state == 0), 1, 0)\n",
    "    return np.sum(np.where(mask, flat_state.cumsum(axis=0), 0))\n",
    "\n",
    "def train(num_episodes = 1000, human=False): \n",
    "    for i_episode in range(num_episodes):\n",
    "        # Initialize the environment and state\n",
    "        height, lines = 0, 0\n",
    "        env.reset()\n",
    "        last_state = get_screen(human=human)\n",
    "        state = get_screen(human=human)\n",
    "        hole_count = 0 \n",
    "        hole_reward = 0\n",
    "        tower_count = 0 \n",
    "        tower_reward = 0\n",
    "        if not human:\n",
    "            state_array = np.array([last_state] * MULTISTEP_PARAM)\n",
    "            reward_array = np.array([0] * MULTISTEP_PARAM)\n",
    "            reward_sum = 0\n",
    "            array_pos = 0\n",
    "            next_array_pos = 1\n",
    "            warmup = 1\n",
    "        for t in count():\n",
    "\n",
    "            # Select and perform an action\n",
    "            action = select_action(state, deterministic=human)\n",
    "            # Can only perform an action once every three frames anyway...\n",
    "            state, _, done, info = env.step(action.item())\n",
    "            piece_fell = did_piece_fall(env)\n",
    "            if not done:\n",
    "                state, _, done, info = env.step(0)\n",
    "                piece_fell = (piece_fell or did_piece_fall(env))\n",
    "            if not done:\n",
    "                state, _, done, info = env.step(0)\n",
    "                piece_fell = (piece_fell or did_piece_fall(env))\n",
    "\n",
    "            # Observe new state\n",
    "            state = get_screen(state, human)\n",
    "            state_array[array_pos] = state\n",
    "            \n",
    "            # Start messing with rewards\n",
    "            if piece_fell:\n",
    "                # Holes\n",
    "                new_holes = num_holes(last_state)\n",
    "                holes_reward = new_holes - hole_count\n",
    "                hole_count = new_holes\n",
    "                # Towers\n",
    "                new_towers = num_holy_towers(last_state)\n",
    "                tower_reward = new_towers - tower_count\n",
    "                tower_count = new_towers\n",
    "            else:\n",
    "                holes_reward = 0\n",
    "                tower_reward = 0\n",
    "                \n",
    "            reward_single = create_reward(env, piece_fell, action, done, info, height, lines, holes_reward, tower_reward)\n",
    "            reward_sum = (MULISTEP_GAMMA * reward_sum) + reward_single - (MULISTEP_GAMMA ** MULTISTEP_PARAM) * reward_array[array_pos]\n",
    "            reward_array[array_pos] = reward_single\n",
    "            reward_sum = torch.tensor([reward_sum], device=device).type(torch.float)\n",
    "            \n",
    "            if not human:\n",
    "                # Store the transition in memory\n",
    "                if warmup > MULTISTEP_PARAM:\n",
    "                    with torch.no_grad():\n",
    "                        loss = compute_loss_single(state_array[next_array_pos], action, state, reward_sum) ** ((1 - curr_eps(steps_done)) / 2 + 0.05)\n",
    "                    memory.push(state_array[next_array_pos], action, state, reward_sum, bias=np.array([loss.cpu()])[0])\n",
    "                \n",
    "                # Perform one step of the optimization (on the target network)\n",
    "                optimize_model()\n",
    "                if done:\n",
    "                    episode_durations.append(t + 1)\n",
    "                    lines_cleared.append(lines)\n",
    "                    plot_durations('latest.png')\n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            # Set up params for next cycle\n",
    "            height = info['height']\n",
    "            lines = env.unwrapped.game.complete_lines\n",
    "            last_state = state\n",
    "            array_pos = (array_pos + 1) % MULTISTEP_PARAM\n",
    "            next_array_pos = (next_array_pos + 1) % MULTISTEP_PARAM\n",
    "            warmup += 1\n",
    "            \n",
    "        if not human:\n",
    "            # Update the target network, copying all weights and biases in DQN\n",
    "            if i_episode % TARGET_UPDATE == 0:\n",
    "                target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "def watch_model(rounds=1000):\n",
    "    with torch.no_grad():\n",
    "        train(rounds, human=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing\n",
    "train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 0\n",
    "while True:\n",
    "    train(2000)\n",
    "    torch.save(policy_net, f'{load_net_prefix}{idx}')\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-ae85c8d89772>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwatch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-b76b13ce82ec>\u001b[0m in \u001b[0;36mwatch_model\u001b[0;34m(rounds)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwatch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhuman\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-1246f382f662>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_episodes, human)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhuman\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# Can only perform an action once every three frames anyway...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mpiece_fell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdid_piece_fall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_episode_started_at\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym_tetris/tetris_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \"\"\"\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_number\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# if this step has passed the max number, set the episode to done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym_tetris/tetris.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_board\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_next_piece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_piece\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfalling_piece\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_piece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfalling_piece\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym_tetris/tetris.py\u001b[0m in \u001b[0;36m_draw_next_piece\u001b[0;34m(self, piece)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_screen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_surf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_rect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;31m# draw the \"next\" piece preview\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_piece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpiece\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixel_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTATUS_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixel_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNEXT_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;31m# MARK: private movement methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym_tetris/tetris.py\u001b[0m in \u001b[0;36m_draw_piece\u001b[0;34m(self, piece, pixel_x, pixel_y)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpixel_x\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox_x\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mBOXSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpixel_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox_y\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mBOXSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpiece\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'color'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_draw_next_piece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpiece\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym_tetris/tetris.py\u001b[0m in \u001b[0;36m_draw_box\u001b[0;34m(self, box_x, box_y, color, pixel_x, pixel_y)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;31m# draw the smaller depth perspective effect box\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mdepth_rect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpixel_x\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixel_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBOXSIZE\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBOXSIZE\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_screen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLIGHTCOLORS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_rect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_draw_board\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "watch_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
