{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tetris Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.4\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import gym_tetris\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym_tetris.make('Tetris-v0')\n",
    "BATCH_SIZE = 196\n",
    "GAMMA = 0.9\n",
    "MULISTEP_GAMMA = 0.98\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.01\n",
    "EPS_DECAY = 50000000\n",
    "TARGET_UPDATE = 50\n",
    "NUM_STATES = env.action_space.n\n",
    "MULTISTEP_PARAM = 5\n",
    "MOVEMENT_COST = 0.01\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "def curr_eps(steps):\n",
    "    return EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps / EPS_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.bias = []\n",
    "        self.bias_sum = 0\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args, bias=1):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "            self.bias.append(None)\n",
    "            self.bias_sum += bias\n",
    "        else:\n",
    "            # Don't add if small bias\n",
    "            if bias < self.bias_sum / len(self.memory) * (curr_eps(steps_done) - EPS_END):\n",
    "                return\n",
    "            self.bias_sum -= self.bias[self.position]\n",
    "            self.bias_sum += bias\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.bias[self.position] = bias\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size, biased=True):\n",
    "        if biased:\n",
    "            choice_indices = np.random.choice(len(self.memory), size=batch_size, replace=False, p=np.array(self.bias) / self.bias_sum)\n",
    "            return [self.memory[i] for i in choice_indices]\n",
    "        else:\n",
    "            return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I figure, if we've abstracted away the problem, we can get rid of the convolutional \n",
    "#  layers and make it fully dense...\n",
    "# Will add those in later when we can get the toy model to work, I guess\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, h, w):\n",
    "        super(DQN, self).__init__()\n",
    "        self.input_layer_width = h * w\n",
    "        self.fc1 = nn.Linear(self.input_layer_width, self.input_layer_width * 3)\n",
    "        self.fc2 = nn.Linear(self.input_layer_width * 3, self.input_layer_width * 8)\n",
    "        self.fc3 = nn.Linear(self.input_layer_width * 8, self.input_layer_width * 3)\n",
    "        self.fc4 = nn.Linear(self.input_layer_width * 3, self.input_layer_width)\n",
    "        self.output_layer = nn.Linear(self.input_layer_width, 12)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x.view(x.size(0), -1)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_state(state_var):\n",
    "    \"\"\"Returns a greyscale image with pixels taking values in [0,1]. Also adds a batch dimension\"\"\"\n",
    "    greyscale  = np.sum(state_var, axis=2) / (3 * 255)\n",
    "    return greyscale\n",
    "\n",
    "def compress_board(state):\n",
    "    \"\"\"Assumes board greyscale\"\"\"\n",
    "    small_board = state[10:423:20, 20:213:20]\n",
    "    next_piece = state[180:241:20, 235:296:20]\n",
    "    return small_board, next_piece\n",
    "\n",
    "def combine_board_and_piece(board, piece):\n",
    "    return board\n",
    "\n",
    "def get_screen(screen=None, human=False):\n",
    "    if screen is None and not human:\n",
    "        screen = env.render(mode='rgb_array')\n",
    "    if human:\n",
    "        bla = env.render()\n",
    "        screen = env.env.screen\n",
    "        \n",
    "    # Turn greyscale\n",
    "    screen = clean_state(screen)\n",
    "    \n",
    "    # Compress\n",
    "    screen, piece = compress_board(screen)\n",
    "    screen = combine_board_and_piece(screen, piece)\n",
    "    \n",
    "    # Resize and add a batch dimension (BCHW)\n",
    "    tensor = torch.from_numpy(screen).unsqueeze(0).unsqueeze(0)\n",
    "    # Push to floats on GPU\n",
    "    return tensor.type(torch.FloatTensor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fell back to creating a new net...\n"
     ]
    }
   ],
   "source": [
    "load_net_prefix = './models/tetrisBot6v'\n",
    "load_net_number = 0\n",
    "net_to_load = f'{load_net_prefix}{load_net_number}'\n",
    "try:\n",
    "    policy_net = torch.load(net_to_load)\n",
    "    policy_net.eval()\n",
    "    target_net = torch.load(net_to_load)\n",
    "    target_net.eval()\n",
    "    print(f'{net_to_load} loaded...')\n",
    "except:\n",
    "    policy_net = DQN(screen_height, screen_width).to(device)\n",
    "    target_net = DQN(screen_height, screen_width).to(device)\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    target_net.eval()\n",
    "    print(f'Fell back to creating a new net...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(policy_net.parameters(), lr=10**-4)\n",
    "memory = ReplayMemory(100000)\n",
    "\n",
    "def select_action(state, deterministic=False):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = curr_eps(steps_done)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold and not deterministic:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(NUM_STATES)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "lines_cleared = []\n",
    "\n",
    "def plot_durations(save=None):\n",
    "    fig = plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    plt.plot(np.array(lines_cleared) * 200)\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    \n",
    "    if save is not None:\n",
    "        fig.savefig(save, bbox_inches='tight')\n",
    "        \n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "#         display.display(plt.gcf())\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_single(state, action, next_state, reward):\n",
    "    return _compute_loss(state, action, next_state, reward, batch_size=1)\n",
    "\n",
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE, biased=False)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    next_state_batch = torch.cat(batch.next_state)\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Huber loss\n",
    "    loss = _compute_loss(state_batch, action_batch, next_state_batch, reward_batch)\n",
    "    \n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n",
    "\n",
    "def _compute_loss(_state, _action, _next_state, _reward, batch_size=BATCH_SIZE):\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(_state).gather(1, _action)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "#     next_state_values = target_net(_next_state).max(1)[0].detach()\n",
    "    \n",
    "#     Double Q learning:\n",
    "    next_state_values = target_net(get_screen())[0][policy_net(get_screen()).argmax(1)[0]].detach()\n",
    "    \n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + _reward\n",
    "\n",
    "    # Compute Huber loss\n",
    "    return F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def did_piece_fall(env):\n",
    "    return (env.unwrapped.game.falling_piece is None)\n",
    "\n",
    "def create_reward(this_env, block_placed, action, is_done, info,\n",
    "                  old_height, old_lines, hole_count=0, hole_towers=0,\n",
    "                  include_height=True, include_score=True, include_holes=True, include_towers=True):\n",
    "    \"\"\"Assumes states are 21 x 10\"\"\"\n",
    "    if not block_placed:\n",
    "        # Punish a little for doing something that isn't the empty move\n",
    "        if action == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return -MOVEMENT_COST\n",
    "    if is_done:\n",
    "        return -50.0\n",
    "    \n",
    "    total_reward = 0\n",
    "    if include_height:\n",
    "        if info['height'] > old_height: \n",
    "            # Punish a little more the closer you are to the top\n",
    "            total_reward += (1 + info['height'] / 10) * (old_height - info['height']) /3\n",
    "    \n",
    "    line_diff = this_env.unwrapped.game.complete_lines - old_lines\n",
    "    if include_score and line_diff != 0:\n",
    "        total_reward += 20 * 2 ** (line_diff)\n",
    "    \n",
    "    if include_holes:\n",
    "        total_reward -= hole_count * 1.5\n",
    "    if include_towers:\n",
    "        total_reward -= include_towers\n",
    "    \n",
    "    return total_reward\n",
    "\n",
    "def num_holes(state):\n",
    "    flat_state = np.where(state.cpu() > 0, 1, 0).squeeze(0).squeeze(0)\n",
    "    return np.sum(np.where((np.roll(flat_state, flat_state.shape[1]) > 0) & (flat_state == 0), 1, 0)[1:, :])\n",
    "\n",
    "def num_holy_towers(state):\n",
    "    \"\"\"This is a fucking work of art\"\"\"\n",
    "    flat_state = np.where(state.cpu() > 0, 1, 0).squeeze(0).squeeze(0)\n",
    "    mask = np.where((np.roll(flat_state, flat_state.shape[1]) > 0) & (flat_state == 0), 1, 0)\n",
    "    return np.sum(np.where(mask, flat_state.cumsum(axis=0), 0))\n",
    "\n",
    "def train(num_episodes = 1000, human=False): \n",
    "    for i_episode in range(num_episodes):\n",
    "        # Initialize the environment and state\n",
    "        height, lines = 0, 0\n",
    "        env.reset()\n",
    "        last_state = get_screen(human=human)\n",
    "        state = get_screen(human=human)\n",
    "        hole_count = 0 \n",
    "        hole_reward = 0\n",
    "        tower_count = 0 \n",
    "        tower_reward = 0\n",
    "        if not human:\n",
    "            state_array = [last_state] * MULTISTEP_PARAM\n",
    "            reward_array = [0] * MULTISTEP_PARAM\n",
    "            \n",
    "            reward_sum = 0\n",
    "            array_pos = 0\n",
    "            next_array_pos = 1\n",
    "            warmup = 1\n",
    "        for t in count():\n",
    "\n",
    "            # Select and perform an action\n",
    "            action = select_action(state, deterministic=human)\n",
    "            # Can only perform an action once every three frames anyway...\n",
    "            state, _, done, info = env.step(action.item())\n",
    "            piece_fell = did_piece_fall(env)\n",
    "            if not done:\n",
    "                state, _, done, info = env.step(0)\n",
    "                piece_fell = (piece_fell or did_piece_fall(env))\n",
    "            if not done:\n",
    "                state, _, done, info = env.step(0)\n",
    "                piece_fell = (piece_fell or did_piece_fall(env))\n",
    "\n",
    "            # Observe new state\n",
    "            state = get_screen(state, human)\n",
    "            state_array[array_pos] = state\n",
    "            \n",
    "            if not human:\n",
    "                # Rewards\n",
    "                if piece_fell:\n",
    "                    # Holes\n",
    "                    new_holes = num_holes(last_state)\n",
    "                    holes_reward = new_holes - hole_count\n",
    "                    hole_count = new_holes\n",
    "                    # Towers\n",
    "                    new_towers = num_holy_towers(last_state)\n",
    "                    tower_reward = new_towers - tower_count\n",
    "                    tower_count = new_towers\n",
    "                else:\n",
    "                    holes_reward = 0\n",
    "                    tower_reward = 0\n",
    "                    \n",
    "                reward_single = create_reward(env, piece_fell, action, done, info, height, lines, holes_reward, tower_reward)\n",
    "                reward_sum = (MULISTEP_GAMMA * reward_sum) + reward_single - (MULISTEP_GAMMA ** MULTISTEP_PARAM) * reward_array[array_pos]\n",
    "                reward_array[array_pos] = reward_single\n",
    "                print(reward_array, reward_sum, reward_single, array_pos)\n",
    "                reward_sum = torch.tensor([reward_sum], device=device).type(torch.float)\n",
    "                \n",
    "                # Store the transition in memory\n",
    "                if warmup > MULTISTEP_PARAM:\n",
    "                    with torch.no_grad():\n",
    "                        loss = compute_loss_single(state_array[next_array_pos], action, state, reward_sum) ** ((1 - curr_eps(steps_done)) / 2 + 0.05)\n",
    "                    memory.push(state_array[next_array_pos], action, state, reward_sum, bias=np.array([loss.cpu()])[0])\n",
    "                \n",
    "                # Perform one step of the optimization (on the target network)\n",
    "                optimize_model()\n",
    "                if done:\n",
    "                    episode_durations.append(t + 1)\n",
    "                    lines_cleared.append(lines)\n",
    "                    plot_durations('latest.png')\n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            # Set up params for next cycle\n",
    "            height = info['height']\n",
    "            lines = env.unwrapped.game.complete_lines\n",
    "            last_state = state\n",
    "            array_pos = (array_pos + 1) % MULTISTEP_PARAM\n",
    "            next_array_pos = (next_array_pos + 1) % MULTISTEP_PARAM\n",
    "            warmup += 1\n",
    "            \n",
    "        if not human:\n",
    "            # Update the target network, copying all weights and biases in DQN\n",
    "            if i_episode % TARGET_UPDATE == 0:\n",
    "                target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "def watch_model(rounds=1000):\n",
    "    with torch.no_grad():\n",
    "        train(rounds, human=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0] 0.0 0 0\n",
      "[0, -0.01, 0, 0, 0] tensor([-0.0100], device='cuda:0') -0.01 1\n",
      "[0, -0.01, -0.01, 0, 0] tensor([-0.0198], device='cuda:0') -0.01 2\n",
      "[0, -0.01, -0.01, -0.01, 0] tensor([-0.0294], device='cuda:0') -0.01 3\n",
      "[0, -0.01, -0.01, -0.01, -0.01] tensor([-0.0388], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 4\n",
      "[0, -0.01, -0.01, -0.01, -0.01] tensor([-0.0380], device='cuda:0') 0 0\n",
      "[0, -0.01, -0.01, -0.01, -0.01] tensor([-0.0382], device='cuda:0') -0.01 1\n",
      "[0, -0.01, -0.01, -0.01, -0.01] tensor([-0.0384], device='cuda:0') -0.01 2\n",
      "[0, -0.01, -0.01, -0.01, -0.01] tensor([-0.0386], device='cuda:0') -0.01 3\n",
      "[0, -0.01, -0.01, -0.01, -0.01] tensor([-0.0388], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0380], device='cuda:0') 0 4\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0382], device='cuda:0') -0.01 0\n",
      "[-0.01, 0, -0.01, -0.01, 0] tensor([-0.0284], device='cuda:0') 0 1\n",
      "[-0.01, 0, 0, -0.01, 0] tensor([-0.0188], device='cuda:0') 0 2\n",
      "[-0.01, 0, 0, -0.01, 0] tensor([-0.0194], device='cuda:0') -0.01 3\n",
      "[-0.01, 0, 0, -0.01, 0] tensor([-0.0190], device='cuda:0') 0 4\n",
      "[-0.01, 0, 0, -0.01, 0] tensor([-0.0196], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, 0, -0.01, 0] tensor([-0.0292], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0386], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0388], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 4\n",
      "[-2.8666666666666663, -0.01, -0.01, -0.01, -0.01] tensor([-2.9047], device='cuda:0') -2.8666666666666663 0\n",
      "[-2.8666666666666663, -0.01, -0.01, -0.01, -0.01] tensor([-2.8476], device='cuda:0') -0.01 1\n",
      "[-2.8666666666666663, -0.01, 0, -0.01, -0.01] tensor([-2.7816], device='cuda:0') 0 2\n",
      "[-2.8666666666666663, -0.01, 0, -0.01, -0.01] tensor([-2.7269], device='cuda:0') -0.01 3\n",
      "[-2.8666666666666663, -0.01, 0, -0.01, -0.01] tensor([-2.6733], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, 0, -0.01, -0.01] tensor([-0.0386], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, 0, -0.01, -0.01] tensor([-0.0388], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 0\n",
      "[-0.01, 0, -0.01, -0.01, -0.01] tensor([-0.0380], device='cuda:0') 0 1\n",
      "[-0.01, 0, 0, -0.01, -0.01] tensor([-0.0282], device='cuda:0') 0 2\n",
      "[-0.01, 0, 0, 0, -0.01] tensor([-0.0186], device='cuda:0') 0 3\n",
      "[-0.01, 0, 0, 0, -0.01] tensor([-0.0192], device='cuda:0') -0.01 4\n",
      "[0, 0, 0, 0, -0.01] tensor([-0.0098], device='cuda:0') 0 0\n",
      "[0, -0.01, 0, 0, -0.01] tensor([-0.0196], device='cuda:0') -0.01 1\n",
      "[0, -0.01, -0.01, 0, -0.01] tensor([-0.0292], device='cuda:0') -0.01 2\n",
      "[0, -0.01, -0.01, -0.01, -0.01] tensor([-0.0386], device='cuda:0') -0.01 3\n",
      "[0, -0.01, -0.01, -0.01, -0.01] tensor([-0.0388], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, 0, -0.01, -0.01] tensor([-0.0380], device='cuda:0') 0 2\n",
      "[-0.01, -0.01, 0, -0.01, -0.01] tensor([-0.0382], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, 0, -0.01, 0] tensor([-0.0284], device='cuda:0') 0 4\n",
      "[-0.01, -0.01, 0, -0.01, 0] tensor([-0.0288], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, 0, -0.01, 0] tensor([-0.0292], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0386], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0388], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, 0, -0.01] tensor([-0.0380], device='cuda:0') 0 3\n",
      "[-0.01, -0.01, -0.01, 0, -0.01] tensor([-0.0382], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, 0, -0.01] tensor([-0.0384], device='cuda:0') -0.01 0\n",
      "[-0.01, -4.5, -0.01, 0, -0.01] tensor([-4.5286], device='cuda:0') -4.5 1\n",
      "[-0.01, -4.5, 0, 0, -0.01] tensor([-4.4290], device='cuda:0') 0 2\n",
      "[-0.01, -4.5, 0, -0.01, -0.01] tensor([-4.3504], device='cuda:0') -0.01 3\n",
      "[-0.01, -4.5, 0, -0.01, 0] tensor([-4.2544], device='cuda:0') 0 4\n",
      "[0, -4.5, 0, -0.01, 0] tensor([-4.1603], device='cuda:0') 0 0\n",
      "[0, -0.01, 0, -0.01, 0] tensor([-0.0194], device='cuda:0') -0.01 1\n",
      "[0, -0.01, -0.01, -0.01, 0] tensor([-0.0290], device='cuda:0') -0.01 2\n",
      "[0, -0.01, -0.01, -0.01, 0] tensor([-0.0294], device='cuda:0') -0.01 3\n",
      "[0, -0.01, -0.01, -0.01, 0] tensor([-0.0288], device='cuda:0') 0 4\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0382], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0384], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0386], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0388], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0380], device='cuda:0') 0 4\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0382], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0384], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0386], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0388], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 0\n",
      "[-0.01, -4.0, -0.01, -0.01, -0.01] tensor([-4.0380], device='cuda:0') -4.0 1\n",
      "[-0.01, -4.0, -0.01, -0.01, -0.01] tensor([-3.9582], device='cuda:0') -0.01 2\n",
      "[-0.01, -4.0, -0.01, -0.01, -0.01] tensor([-3.8800], device='cuda:0') -0.01 3\n",
      "[-0.01, -4.0, -0.01, -0.01, -0.01] tensor([-3.8034], device='cuda:0') -0.01 4\n",
      "[-0.01, -4.0, -0.01, -0.01, -0.01] tensor([-3.7283], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, 0, -0.01, -0.01] tensor([-0.0380], device='cuda:0') 0 2\n",
      "[-0.01, -0.01, 0, -0.01, -0.01] tensor([-0.0382], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, 0, -0.01, -0.01] tensor([-0.0384], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, 0, -0.01, -0.01] tensor([-0.0386], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, 0, -0.01, -0.01] tensor([-0.0388], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0380], device='cuda:0') 0 4\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0382], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0384], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0386], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0388], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0380], device='cuda:0') 0 4\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0382], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0384], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0386], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0388], device='cuda:0') -0.01 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 4\n",
      "[0, -0.01, -0.01, -0.01, -0.01] tensor([-0.0380], device='cuda:0') 0 0\n",
      "[0, -0.01, -0.01, -0.01, -0.01] tensor([-0.0382], device='cuda:0') -0.01 1\n",
      "[0, -0.01, -0.01, -0.01, -0.01] tensor([-0.0384], device='cuda:0') -0.01 2\n",
      "[0, -0.01, -0.01, -0.01, -0.01] tensor([-0.0386], device='cuda:0') -0.01 3\n",
      "[0, -0.01, -0.01, -0.01, -2.5] tensor([-2.5288], device='cuda:0') -2.5 4\n",
      "[-0.01, -0.01, -0.01, -0.01, -2.5] tensor([-2.4882], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, -2.5] tensor([-2.4394], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, -2.5] tensor([-2.3916], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, -2.5] tensor([-2.3447], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0380], device='cuda:0') 0 4\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0382], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0384], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0386], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, 0, 0] tensor([-0.0288], device='cuda:0') 0 3\n",
      "[-0.01, -0.01, -0.01, 0, -0.01] tensor([-0.0382], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, 0, -0.01] tensor([-0.0384], device='cuda:0') -0.01 0\n",
      "[-0.01, 0, -0.01, 0, -0.01] tensor([-0.0286], device='cuda:0') 0 1\n",
      "[-0.01, 0, -0.01, 0, -0.01] tensor([-0.0290], device='cuda:0') -0.01 2\n",
      "[-0.01, 0, -0.01, -0.01, -0.01] tensor([-0.0384], device='cuda:0') -0.01 3\n",
      "[-0.01, 0, -0.01, -0.01, -0.01] tensor([-0.0386], device='cuda:0') -0.01 4\n",
      "[-0.01, 0, -0.01, -0.01, -0.01] tensor([-0.0388], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, 0, -0.01, -0.01] tensor([-0.0380], device='cuda:0') 0 2\n",
      "[-0.01, -0.01, 0, -0.01, -0.01] tensor([-0.0382], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, 0, -0.01, -2.5] tensor([-2.5284], device='cuda:0') -2.5 4\n",
      "[0, -0.01, 0, -0.01, -2.5] tensor([-2.4688], device='cuda:0') 0 0\n",
      "[0, 0, 0, -0.01, -2.5] tensor([-2.4104], device='cuda:0') 0 1\n",
      "[0, 0, -0.01, -0.01, -2.5] tensor([-2.3722], device='cuda:0') -0.01 2\n",
      "[0, 0, -0.01, 0, -2.5] tensor([-2.3157], device='cuda:0') 0 3\n",
      "[0, 0, -0.01, 0, -0.01] tensor([-0.0196], device='cuda:0') -0.01 4\n",
      "[-0.01, 0, -0.01, 0, -0.01] tensor([-0.0292], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, 0, -0.01] tensor([-0.0386], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, 0, -0.01] tensor([-0.0388], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, 0, -0.01, -0.01] tensor([-0.0380], device='cuda:0') 0 2\n",
      "[-0.01, -0.01, 0, -0.01, -0.01] tensor([-0.0382], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, 0, -0.01, -0.01] tensor([-0.0384], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, 0, -0.01, -0.01] tensor([-0.0386], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, 0, -0.01, -0.01] tensor([-0.0388], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 4\n",
      "[-1.0, -0.01, -0.01, -0.01, -0.01] tensor([-1.0380], device='cuda:0') -1.0 0\n",
      "[-1.0, -0.01, -0.01, -0.01, -0.01] tensor([-1.0182], device='cuda:0') -0.01 1\n",
      "[-1.0, -0.01, -0.01, -0.01, -0.01] tensor([-0.9988], device='cuda:0') -0.01 2\n",
      "[-1.0, -0.01, -0.01, -0.01, -0.01] tensor([-0.9798], device='cuda:0') -0.01 3\n",
      "[-1.0, -0.01, -0.01, -0.01, -0.01] tensor([-0.9612], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0380], device='cuda:0') 0 4\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0382], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0384], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0386], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0388], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0380], device='cuda:0') 0 4\n",
      "[-4.0, -0.01, -0.01, -0.01, 0] tensor([-4.0282], device='cuda:0') -4.0 0\n",
      "[-4.0, -0.01, -0.01, -0.01, 0] tensor([-3.9486], device='cuda:0') -0.01 1\n",
      "[-4.0, -0.01, -0.01, -0.01, 0] tensor([-3.8706], device='cuda:0') -0.01 2\n",
      "[-4.0, -0.01, -0.01, -0.01, 0] tensor([-3.7942], device='cuda:0') -0.01 3\n",
      "[-4.0, -0.01, -0.01, -0.01, -0.01] tensor([-3.7283], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 4\n",
      "[0, -0.01, -0.01, -0.01, -0.01] tensor([-0.0380], device='cuda:0') 0 0\n",
      "[0, -0.01, -0.01, -0.01, -0.01] tensor([-0.0382], device='cuda:0') -0.01 1\n",
      "[0, -0.01, -0.01, -0.01, -0.01] tensor([-0.0384], device='cuda:0') -0.01 2\n",
      "[0, -0.01, -0.01, 0, -0.01] tensor([-0.0286], device='cuda:0') 0 3\n",
      "[0, -0.01, -0.01, 0, -0.01] tensor([-0.0290], device='cuda:0') -0.01 4\n",
      "[0, -0.01, -0.01, 0, -0.01] tensor([-0.0284], device='cuda:0') 0 0\n",
      "[0, -0.01, -0.01, 0, -0.01] tensor([-0.0288], device='cuda:0') -0.01 1\n",
      "[0, -0.01, -0.01, 0, -0.01] tensor([-0.0292], device='cuda:0') -0.01 2\n",
      "[0, -0.01, -0.01, 0, -0.01] tensor([-0.0286], device='cuda:0') 0 3\n",
      "[0, -0.01, -0.01, 0, -0.7666666666666666] tensor([-0.7857], device='cuda:0') -0.7666666666666666 4\n",
      "[-0.01, -0.01, -0.01, 0, -0.7666666666666666] tensor([-0.7800], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, 0, -0.7666666666666666] tensor([-0.7653], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, 0, -0.7666666666666666] tensor([-0.7510], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.7666666666666666] tensor([-0.7460], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, 0, -0.01] tensor([-0.0380], device='cuda:0') 0 3\n",
      "[-0.01, -0.01, -0.01, 0, -0.01] tensor([-0.0382], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, 0, -0.01] tensor([-0.0384], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, 0, -0.01] tensor([-0.0386], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, 0, 0, -0.01] tensor([-0.0288], device='cuda:0') 0 2\n",
      "[-0.01, -0.01, 0, -0.01, -0.01] tensor([-0.0382], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, 0, -0.01, -0.01] tensor([-0.0384], device='cuda:0') -0.01 4\n",
      "[-4.0, -0.01, 0, -0.01, -0.01] tensor([-4.0286], device='cuda:0') -4.0 0\n",
      "[-4.0, -0.01, 0, -0.01, -0.01] tensor([-3.9490], device='cuda:0') -0.01 1\n",
      "[-4.0, -0.01, 0, -0.01, -0.01] tensor([-3.8700], device='cuda:0') 0 2\n",
      "[-4.0, -0.01, 0, -0.01, -0.01] tensor([-3.7936], device='cuda:0') -0.01 3\n",
      "[-4.0, -0.01, 0, -0.01, -0.01] tensor([-3.7187], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, 0, -0.01, -0.01] tensor([-0.0386], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, 0, -0.01, -0.01] tensor([-0.0388], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, 0, -0.01] tensor([-0.0380], device='cuda:0') 0 3\n",
      "[-0.01, -0.01, -0.01, 0, 0] tensor([-0.0282], device='cuda:0') 0 4\n",
      "[-0.01, -0.01, -0.01, 0, 0] tensor([-0.0286], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, 0, 0] tensor([-0.0290], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, 0, 0] tensor([-0.0294], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0388], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.16666666666666663, -0.01, -0.01] tensor([-0.2047], device='cuda:0') -0.16666666666666663 2\n",
      "[-0.01, -0.01, -0.16666666666666663, -0.01, -0.01] tensor([-0.2016], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.16666666666666663, -0.01, -0.01] tensor([-0.1985], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.16666666666666663, -0.01, -0.01] tensor([-0.1955], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.16666666666666663, -0.01, -0.01] tensor([-0.1925], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0380], device='cuda:0') 0 4\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0382], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0384], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0386], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, 0] tensor([-0.0388], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -4.8, -0.01, -0.01] tensor([-4.8380], device='cuda:0') -4.8 2\n",
      "[-0.01, -0.01, -4.8, -0.01, -0.01] tensor([-4.7422], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -4.8, -0.01, -0.01] tensor([-4.6484], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -4.8, -0.01, -0.01] tensor([-4.5563], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -4.8, -0.01, -0.01] tensor([-4.4662], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 0\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 1\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 2\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 3\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 4\n",
      "[-0.01, -0.01, -0.01, -0.01, -0.01] tensor([-0.0480], device='cuda:0') -0.01 0\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a950a7324303>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{load_net_prefix}{idx}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-4f4d68e46f99>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_episodes, human)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhuman\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;31m# Can only perform an action once every three frames anyway...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0mpiece_fell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdid_piece_fall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_episode_started_at\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym_tetris/tetris_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \"\"\"\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_number\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# if this step has passed the max number, set the episode to done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym_tetris/tetris.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'height'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym_tetris/tetris.py\u001b[0m in \u001b[0;36mscreen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;34m\"\"\"Return the screen as a NumPy array.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurfarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_screen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pygame/surfarray.py\u001b[0m in \u001b[0;36marray3d\u001b[0;34m(surface)\u001b[0m\n\u001b[1;32m    127\u001b[0m     method).\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnumpysf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray3d\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msurface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpixels3d\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msurface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pygame/_numpysurfarray.py\u001b[0m in \u001b[0;36marray3d\u001b[0;34m(surface)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msurface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0msurface_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "while True:\n",
    "    train(2000)\n",
    "    torch.save(policy_net, f'{load_net_prefix}{idx}')\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-0.0475], device='cuda:0'),\n",
       " tensor([-0.0465], device='cuda:0'),\n",
       " tensor([-0.0556], device='cuda:0'),\n",
       " tensor([-0.0645], device='cuda:0'),\n",
       " tensor([-0.0732], device='cuda:0'),\n",
       " tensor([-0.0817], device='cuda:0'),\n",
       " tensor([-0.0901], device='cuda:0'),\n",
       " tensor([-0.0983], device='cuda:0'),\n",
       " tensor([-0.1063], device='cuda:0'),\n",
       " tensor([-0.1142], device='cuda:0'),\n",
       " tensor([-0.1219], device='cuda:0'),\n",
       " tensor([-0.1195], device='cuda:0'),\n",
       " tensor([-0.1271], device='cuda:0'),\n",
       " tensor([-0.1245], device='cuda:0'),\n",
       " tensor([-0.1321], device='cuda:0'),\n",
       " tensor([-0.1394], device='cuda:0'),\n",
       " tensor([-0.1466], device='cuda:0'),\n",
       " tensor([-0.1537], device='cuda:0'),\n",
       " tensor([-0.1606], device='cuda:0'),\n",
       " tensor([-0.1674], device='cuda:0'),\n",
       " tensor([-0.1741], device='cuda:0'),\n",
       " tensor([-0.1806], device='cuda:0'),\n",
       " tensor([-0.1870], device='cuda:0'),\n",
       " tensor([-0.1932], device='cuda:0'),\n",
       " tensor([-0.1994], device='cuda:0'),\n",
       " tensor([-0.2054], device='cuda:0'),\n",
       " tensor([-0.2113], device='cuda:0'),\n",
       " tensor([-0.2070], device='cuda:0'),\n",
       " tensor([-0.2129], device='cuda:0'),\n",
       " tensor([-0.2186], device='cuda:0'),\n",
       " tensor([-0.2143], device='cuda:0'),\n",
       " tensor([-0.2100], device='cuda:0'),\n",
       " tensor([-0.2158], device='cuda:0'),\n",
       " tensor([-0.2215], device='cuda:0'),\n",
       " tensor([-0.0475], device='cuda:0'),\n",
       " tensor([-0.0565], device='cuda:0'),\n",
       " tensor([-0.0554], device='cuda:0'),\n",
       " tensor([-0.0643], device='cuda:0'),\n",
       " tensor([-0.0730], device='cuda:0'),\n",
       " tensor([-0.0815], device='cuda:0'),\n",
       " tensor([-0.0899], device='cuda:0'),\n",
       " tensor([-0.0981], device='cuda:0'),\n",
       " tensor([-0.0961], device='cuda:0'),\n",
       " tensor([-0.1042], device='cuda:0'),\n",
       " tensor([-0.1021], device='cuda:0'),\n",
       " tensor([-0.1101], device='cuda:0'),\n",
       " tensor([-0.1179], device='cuda:0'),\n",
       " tensor([-0.1255], device='cuda:0'),\n",
       " tensor([-0.1330], device='cuda:0'),\n",
       " tensor([-0.1404], device='cuda:0'),\n",
       " tensor([-0.1476], device='cuda:0'),\n",
       " tensor([-0.1546], device='cuda:0'),\n",
       " tensor([-0.1615], device='cuda:0'),\n",
       " tensor([-0.1683], device='cuda:0'),\n",
       " tensor([-0.1649], device='cuda:0'),\n",
       " tensor([-0.1716], device='cuda:0'),\n",
       " tensor([-0.1782], device='cuda:0'),\n",
       " tensor([-0.1846], device='cuda:0'),\n",
       " tensor([-0.1809], device='cuda:0'),\n",
       " tensor([-0.1873], device='cuda:0'),\n",
       " tensor([-0.1936], device='cuda:0'),\n",
       " tensor([-0.1997], device='cuda:0'),\n",
       " tensor([-0.2057], device='cuda:0'),\n",
       " tensor([-0.2016], device='cuda:0'),\n",
       " tensor([-0.1976], device='cuda:0'),\n",
       " tensor([-0.2036], device='cuda:0'),\n",
       " tensor([-0.2095], device='cuda:0'),\n",
       " tensor([-0.2053], device='cuda:0'),\n",
       " tensor([-0.2112], device='cuda:0'),\n",
       " tensor([-0.2070], device='cuda:0'),\n",
       " tensor([-0.2129], device='cuda:0'),\n",
       " tensor([-1.5753], device='cuda:0'),\n",
       " tensor([-1.5538], device='cuda:0'),\n",
       " tensor([-1.5327], device='cuda:0'),\n",
       " tensor([-1.5120], device='cuda:0'),\n",
       " tensor([-1.4918], device='cuda:0'),\n",
       " tensor([-0.5680], device='cuda:0'),\n",
       " tensor([-0.5667], device='cuda:0'),\n",
       " tensor([-0.5654], device='cuda:0'),\n",
       " tensor([-0.5640], device='cuda:0'),\n",
       " tensor([-0.5628], device='cuda:0'),\n",
       " tensor([-0.5615], device='cuda:0'),\n",
       " tensor([-0.5603], device='cuda:0'),\n",
       " tensor([-0.5591], device='cuda:0'),\n",
       " tensor([-0.5579], device='cuda:0'),\n",
       " tensor([-0.5567], device='cuda:0'),\n",
       " tensor([-0.5456], device='cuda:0'),\n",
       " tensor([-0.5447], device='cuda:0'),\n",
       " tensor([-0.5338], device='cuda:0'),\n",
       " tensor([-0.5331], device='cuda:0'),\n",
       " tensor([-0.5325], device='cuda:0'),\n",
       " tensor([-0.5318], device='cuda:0'),\n",
       " tensor([-0.5212], device='cuda:0'),\n",
       " tensor([-0.5207], device='cuda:0'),\n",
       " tensor([-0.5203], device='cuda:0'),\n",
       " tensor([-0.5199], device='cuda:0'),\n",
       " tensor([-0.5195], device='cuda:0'),\n",
       " tensor([-0.5191], device='cuda:0'),\n",
       " tensor([-0.5188], device='cuda:0'),\n",
       " tensor([-0.5184], device='cuda:0')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x.reward) for x in memory.memory[:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(memory.memory[10].state.cpu()>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-ae85c8d89772>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwatch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-b76b13ce82ec>\u001b[0m in \u001b[0;36mwatch_model\u001b[0;34m(rounds)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwatch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhuman\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-1246f382f662>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_episodes, human)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhuman\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# Can only perform an action once every three frames anyway...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mpiece_fell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdid_piece_fall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_episode_started_at\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym_tetris/tetris_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \"\"\"\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_number\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# if this step has passed the max number, set the episode to done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym_tetris/tetris.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_board\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_next_piece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_piece\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfalling_piece\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_piece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfalling_piece\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym_tetris/tetris.py\u001b[0m in \u001b[0;36m_draw_next_piece\u001b[0;34m(self, piece)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_screen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_surf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_rect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;31m# draw the \"next\" piece preview\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_piece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpiece\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixel_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTATUS_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixel_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNEXT_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;31m# MARK: private movement methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym_tetris/tetris.py\u001b[0m in \u001b[0;36m_draw_piece\u001b[0;34m(self, piece, pixel_x, pixel_y)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpixel_x\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox_x\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mBOXSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpixel_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox_y\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mBOXSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpiece\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'color'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_draw_next_piece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpiece\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym_tetris/tetris.py\u001b[0m in \u001b[0;36m_draw_box\u001b[0;34m(self, box_x, box_y, color, pixel_x, pixel_y)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;31m# draw the smaller depth perspective effect box\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mdepth_rect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpixel_x\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixel_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBOXSIZE\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBOXSIZE\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_screen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLIGHTCOLORS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_rect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_draw_board\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "watch_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
